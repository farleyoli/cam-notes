\documentclass[a4paper]{article}

\def\npart {IA}
\def\nterm {Michaelmas}
\def\nyear {2014}
\def\nlecturer {A.\ G.\ Thomason}
\def\ncourse {Numbers and Sets}

\input{header}

\begin{document}
\maketitle
{
  \small
  \noindent\textbf{Introduction to number systems and logic}\\
  Overview of the natural numbers, integers, real numbers, rational and irrational numbers, algebraic and transcendental numbers. Brief discussion of complex numbers; statement of the Fundamental Theorem of Algebra.

  \vspace{5pt}
  \noindent Ideas of axiomatic systems and proof within mathematics; the need for proof; the role of counter-examples in mathematics. Elementary logic; implication and negation; examples of negation of compound statements. Proof by contradiction.\hspace*{\fill}[2]

  \vspace{10pt}
  \noindent\textbf{Sets, relations and functions}\\
  Union, intersection and equality of sets. Indicator (characteristic) functions; their use in establishing set identities. Functions; injections, surjections and bijections. Relations, and equivalence relations. Counting the combinations or permutations of a set. The Inclusion-Exclusion Principle.\hspace*{\fill}[4]

  \vspace{10pt}
  \noindent\textbf{The integers}\\
  The natural numbers: mathematical induction and the well-ordering principle. Examples, including the Binomial Theorem.\hspace*{\fill}[2]

  \vspace{10pt}
  \noindent\textbf{Elementary number theory}\\
  Prime numbers: existence and uniqueness of prime factorisation into primes; highest common factors and least common multiples. Euclid's proof of the infinity of primes. Euclid's algorithm. Solution in integers of $ax+by = c$.

  \vspace{5pt}
  \noindent Modular arithmetic (congruences). Units modulo $n$. Chinese Remainder Theorem. Wilson's Theorem; the Fermat-Euler Theorem. Public key cryptography and the RSA algorithm.\hspace*{\fill}[8]

  \vspace{10pt}
  \noindent\textbf{The real numbers}\\
  Least upper bounds; simple examples. Least upper bound axiom. Sequences and series; convergence of bounded monotonic sequences. Irrationality of $\sqrt{2}$ and $e$. Decimal expansions. Construction of a transcendental number.\hspace*{\fill} [4]

  \vspace{10pt}
  \noindent\textbf{Countability and uncountability}\\
  Definitions of finite, infinite, countable and uncountable sets. A countable union of countable sets is countable. Uncountability of R. Non-existence of a bijection from a set to its power set. Indirect proof of existence of transcendental numbers.\hspace*{\fill}[4]}

\tableofcontents

\setcounter{section}{-1}
\section{Introduction}
According to the Faculty, this course is not aimed at teaching you any new knowledge. In particular, the Faculty says
\begin{quote}
  This course is concerned not so much with teaching you new parts of mathematics \ldots
\end{quote}
Instead, this course is intended to teach you about how to do maths properly. The objective of this course is to start from a few \emph{axioms}, which are assumptions about our system, and try to prove everything rigorously from the axioms.

This is different from how mathematics is usually done in secondary school. In secondary school, we just accept that certain statements are true. For example, probably no one rigorously proved to you that each natural number has a unique prime factorization. In this course, \emph{nothing} is handwaved. Everything will be obtained as a logical consequence of the axioms and previous (proven) results.

In the course, you shouldn't focus too much on the content itself. Instead, the major takeaway should be how we do mathematics. In particular, how we construct and present arguments.

The actual content of this course is rather diverse. As the name suggests, the course touches on numbers and sets. The ``numbers'' part is mostly basic number theory, which you may have come across if you have participated in mathematical olympiads. We also study some properties of real numbers, but the actual serious study of real numbers is done in IA Analysis I.

The ``sets'' part starts with some basic definitions of sets, functions and relations, which are really important and will crop up in all courses you will encounter. In some sense, these form the language in which mathematics is written. At the end of the course, we will touch on countability, which tells us how ``big'' a set is.

\section{Proofs and logic}
\subsection{Proofs}
As the first course in pure mathematics, we will have an (informal) look at proofs and logic.

In mathematics, we often want to \emph{prove} things. This is different from most other disciplines. For example, in science, we perform experiments to convince ourselves that our theory is correct. However, no matter how many experiments we do, we still cannot be absolutely sure that our theory is correct. For example, Newtonian mechanics was believed to be correct for a long time, but is nowadays only considered to be an approximation of reality.

On the other hand, when we prove a theorem in mathematics, we are completely sure that the theorem is true. Also, when we actually prove a theorem, (hopefully) we can also understand \emph{why} it is true, and gain further insight.

\begin{defi}[Proof]
  A \emph{proof} is a sequence of true statements, without logical gaps, that is a logical argument establishing some conclusion.
\end{defi}
To prove things, we need to start from some assumptions. These assumptions are known as \emph{axioms}. When we call something an axiom, it does \emph{not} mean that we take these statements to be true without questioning. Instead, we are saying ``if we assume these axioms, then these results hold''. Two people can disagree on what the axioms are and still be friends.

We also tend to define concepts as unambiguously as possible. Of course, just like a dictionary cannot define all words without being circular, we do not define \emph{everything} in mathematics.
To prove things, we have to start somewhere, with some agreed assumptions (\emph{axioms}). We also don't define everything rigorously (or else how could one start speaking?).

In mathematics, we are often concerned about truth. Often, we only care about statements that can take some truth value.
\begin{defi}[Statement]
  A \emph{statement} is a sentence that can have a true value.
\end{defi}

\begin{eg}
  The following are statements:
  \begin{enumerate}
    \item There are infinitely many primes of the form $n^2 + 1$
    \item There is always a prime number between $n$ and $2n$
    \item There is no computer program that can factorize an $n$-digit number in $n^3$ steps
    \item For every polynomial $p(x) = a_nx^n + a_{n - 1}x^{n - 1} + \cdots + a_0$, where $a_i$ are complex numbers, $n\geq 1$, $a_n \not=0$, there exists (possibly complex) $z$ such that $p(z) = 0$
    \item $m\times n = n\times m$ for all natural numbers $n, m$
    \item $2 + 2 = 4$
  \end{enumerate}
  The current status (as of 2015) of these statements are:
  \begin{enumerate}
    \item No one has a proof but it is probably true
    \item This is known to be true
    \item No one knows (related to P = NP problem)
    \item This is known to be true (Fundamental Theorem of Algebra)
    \item This is known to be true
    \item This is known to be true (obviously --- does this need to be proved?)
  \end{enumerate}
\end{eg}

\subsection{Examples of proofs}
Apart from having a proof, it is very important that a proof is \emph{correct}. Here we will look at some examples of proofs and non-proofs.

We first start with a simple example.
\begin{prop}
  For all natural numbers $n$, $n^3 - n$ is a multiple of 3.
\end{prop}

\begin{proof}
  We have $n^3 - n = (n - 1)n(n + 1)$. One of the three consecutive integers is divisible by 3. Hence so is their product.
\end{proof}

\begin{prop}
  If $n^2$ is even, then so is $n$.
\end{prop}

\begin{proof}
  If $n$ is even, then $n = 2k$ for some integer $k$. Then $n^2 = 4k^2$, which is even.
\end{proof}
This is incorrect! We wanted to proof ``$n^2$ is even'' $\Rightarrow $ ``$n$ is even'', but what we proved is ``$n$ is even'' $\Rightarrow$ ``$n^2$ is even'', which are distinct statements.

Instead, a correct proof is as follows:

\begin{proof}
  Suppose $n$ is odd. Then $n = 2k + 1$ for some integer $k$. Then $n^2 = 4k^2 + 4k + 1 = 2(2k^2 + 2) + 1$, which is odd. This contradicts our assumption that $n^2$ is even.
\end{proof}
This is an example of \emph{proof by contradiction}. We assume what we want to prove is false, and show that this leads to nonsense.

\begin{prop}
  The solutions to $x^2 - 5x + 6 = 0$ are $x = 2$ and $x = 3$.
\end{prop}

Note that these are actually 2 different statements:
\begin{enumerate}
  \item $x = 2$ and $x = 3$ are solutions
  \item There are no other solutions
\end{enumerate}
We can write this as an ``if and only if'' statement: $x$ is a solution if and only if $x = 2$ or $x = 3$. Alternatively, we say ``$x$ is a solution iff $x = 2$ or $x = 3$''; or ``$x$ is a solution $\Leftrightarrow$ $x = 2$ or $x = 3$''.

\begin{proof}\leavevmode
  \begin{enumerate}
    \item If $x = 2$ or $x = 3$, then $x - 2 = 0$ or $x - 3 = 0$. So $(x - 2)(x - 3) = 0$.
    \item If $x^2 - 5x + 6 = 0$, then $(x - 2)(x - 3) = 0$. So $x - 2 = 0$ or $x - 3 = 0$. Then $x = 2$ or $x = 3$.
  \end{enumerate}
  Note that the second direction is simply the first argument reversed. We can write this all in one go:
  \begin{align*}
    x = 3 \text{ or }x = 2&\Leftrightarrow x - 3 = 0\text{ or }x - 2 = 0\\
    &\Leftrightarrow (x - 3)(x - 2) = 0\\
    &\Leftrightarrow x^2 - 5x - 6 = 0
  \end{align*}
  Note that we used the ``if and only if'' sign between all lines.
\end{proof}

We'll do another non-proof.
\begin{prop}
  Every positive number is $\geq 1$.
\end{prop}

\begin{proof}
  Let $r$ be the smallest positive real. Then either $r < 1$, $r = 1$ or $r > 1$.

  If $r < 1$, then $0 < r^2 < r$. Contradiction. If $r > 1$, then $0 < \sqrt{r} < r$. Contradiction. So $r = 1$.
\end{proof}
Now this is obviously false, since $0.5 < 1$. The problem with this proof is that the smallest positive real need not exist. So we have to make sure we justify all our claims.

\subsection{Logic}
Mathematics is full of logical statements, which are made of statements and logical connectives. Usually, we use shorthands for the logical connectives.

Let $P$ and $Q$ be statements. Then $P\wedge Q$ stands for ``$P$ and $Q$''; $P\vee Q$ stands for ``$P$ or $Q$''; $P\Rightarrow Q$ stands for ``$P$ implies $Q$''; $P\Leftrightarrow Q$ stands for ``$P$ iff $Q$''; $\neg P$ stands for ``not $P$''. The truth of these statements depends on the truth of $P$ and $Q$ . It can be shown by a truth table:
\begin{center}
  \begin{tabular}{cccccccc}
    \toprule
    $P$ & $Q$ &\quad &$P\wedge Q$ & $P\vee Q$ & $P\Rightarrow Q$ & $P\Leftrightarrow Q$ & $\neg P$ \\
    \midrule
    T & T & & T & T & T & T & F\\
    T & F & & F & T & F & F & F\\
    F & T & & F & T & T & F & T\\
    F & F & & F & F & T & T & T\\
    \bottomrule
  \end{tabular}
\end{center}
Certain logical propositions are equivalent, which we denote using the $\Leftrightarrow$ sign. For example,
\[
  \neg(P\wedge Q) \Leftrightarrow (\neg P\vee \neg Q),
\]
or
\[
  (P\Rightarrow Q) \Leftrightarrow (\neg P\vee Q) \Leftrightarrow (\neg Q\Rightarrow \neg P).
\]
By convention, negation has the highest precedence when bracketing. For example, $\neg P\vee \neg Q$ should be bracketed as $(\neg P)\vee (\neg Q)$.

We also have quantifiers. $(\forall x) P(x)$ means ``for all $x$, $P(x)$ is true'', while $(\exists x) P(x)$ means ``there exists $x$ such that $P(x)$ is true''.

The quantifiers are usually \emph{bounded}, i.e.\ we write $\forall x\in X$ or $\exists x\in X$ to mean ``for all $x$ in the set $X$'' and ``there exists $x$ in the set $X$'' respectively.

Quantifiers are negated as follows:
\[
  \neg (\forall x) P(x) \Leftrightarrow (\exists x)(\neg P(x));
\]
\[
  \neg (\exists x) P(x) \Leftrightarrow (\forall x)(\neg P(x)).
\]
\section{Sets, functions and relations}
In this chapter, we will look at the basic building blocks of mathematics, namely sets, functions and relations. Most of mathematics can be expressed in terms of these notions, and it is helpful to be familiar with the relevant terms.
\subsection{Sets}
\begin{defi}[Set]
  A \emph{set} is a collection of objects, called its \emph{elements} or \emph{members}, without regard to order and without repetition. We write $x \in X$ to mean that $x$ is an element of the set $X$, and $x \notin X$ to mean that it is not.
\end{defi}

\begin{eg}
  If $a = 2$, $b = 1$ and $c = 1$, then the set $\{a, b, c\} = \{1, 2\}$ has only two elements, since $b = c$ and elements are not repeated.
\end{eg}

\begin{notation}
  The following are standard symbols for commonly used number sets:
  \begin{itemize}
    \item $\N = \{1, 2, 3, \cdots \}$, the natural numbers
    \item $\N_0 = \{0, 1, 2, \cdots \}$, the natural numbers together with $0$
    \item $\Z = \{\cdots, -2, -1, 0, 1, 2, \cdots \}$, the integers
    \item $\Q = \left\{\dfrac{a}{b}: a, b\in \Z,\; b \not= 0\right\}$, the rational numbers
    \item $\R$, the real numbers
    \item $\C$, the complex numbers
  \end{itemize}
\end{notation}

\begin{remark}
  It is a matter of convention whether $0$ is considered a natural number. Those who include $0$ usually write $\N$ for $\{0, 1, 2, \cdots\}$ and $\N^+$ for the positive natural numbers. In this course, $\N = \{1, 2, 3, \cdots\}$.
\end{remark}

\begin{defi}[Equality of sets]
  Two sets $A$ and $B$ are \emph{equal}, written $A = B$, if they have the same elements:
  \[
    A = B \iff (\forall x)\;x\in A \Leftrightarrow x\in B.
  \]
\end{defi}

\begin{defi}[Subset]
  Let $A$ and $B$ be sets. We say $A$ is a \emph{subset} of $B$, written $A\subseteq B$, if every element of $A$ is also an element of $B$:
  \[
    A \subseteq B \iff (\forall x)\;x\in A\Rightarrow x\in B.
  \]
\end{defi}

\begin{prop}
  Let $A$ and $B$ be sets. Then $A=B$ if and only if $A\subseteq B$ and $B\subseteq A$.
\end{prop}
\begin{proof}
  If $A = B$, then for every $x$, $x \in A \Leftrightarrow x \in B$. In particular, $x \in A \Rightarrow x \in B$, so $A \subseteq B$, and $x \in B \Rightarrow x \in A$, so $B \subseteq A$.

  Conversely, if $A \subseteq B$ and $B \subseteq A$, then for every $x$, $x \in A \Rightarrow x \in B$ and $x \in B \Rightarrow x \in A$. Hence $x \in A \Leftrightarrow x \in B$, so $A = B$.
\end{proof}

\begin{notation}[Set-builder notation]
  Let $X$ be a set and let $P$ be a property that elements of $X$ may or may not satisfy. We write
  \[
    \{x \in X : P(x)\}
  \]
  for the subset of $X$ consisting of those elements $x$ for which $P(x)$ is true.
\end{notation}

\begin{eg}
  $\{n\in \N : n \text{ is prime}\} = \{2, 3, 5, 7, 11, \ldots\}$ is the set of all prime numbers.
\end{eg}

\begin{defi}[Intersection, union, set difference, symmetric difference and power set]
  Let $A$ and $B$ be sets. We define:
  \begin{itemize}
    \item \emph{Intersection}: $A\cap B = \{x : x\in A \text{ and } x\in B\}$.
    \item \emph{Union}: $A\cup B = \{x : x\in A\text{ or }x\in B\}$.
    \item \emph{Set difference}: $A\setminus B = \{x\in A : x\not\in B\}$.
    \item \emph{Symmetric difference}: $A\Delta B = (A \setminus B) \cup (B \setminus A)$, i.e.\ the set of elements belonging to exactly one of $A$ and $B$.
    \item \emph{Power set}: $\mathcal{P}(A) = \{ X : X\subseteq A\}$, the set of all subsets of $A$.
  \end{itemize}
\end{defi}

\begin{remark}[Russell's paradox]
  One cannot form sets by unrestricted comprehension. For instance, the expression $\{x : x \text{ is a set and } x \notin x\}$ does not define a set, since its existence leads to a contradiction. New sets must be constructed from existing ones via operations such as union, intersection, power set, replacement, and set-builder notation applied to a given set.
\end{remark}

\begin{prop}[Associativity and distributivity]
  Let $A$, $B$ and $C$ be sets. Then:
  \begin{itemize}
    \item $(A\cap B)\cap C = A \cap (B\cap C)$,
    \item $(A\cup B)\cup C = A\cup (B\cup C)$,
    \item $A\cap(B\cup C) = (A\cap B)\cup (A\cap C)$.
  \end{itemize}
\end{prop}
\begin{proof}
  Each identity is proved by showing that an arbitrary element belongs to the left-hand side if and only if it belongs to the right-hand side, using the definitions of $\cap$ and $\cup$.
\end{proof}

\begin{notation}[Arbitrary unions and intersections]
  Let $I$ be a set (called an \emph{index set}) and suppose that for each $\alpha \in I$ we have a set $A_\alpha$. We define
  \[
    \bigcap_{\alpha\in I}A_\alpha = \{x: (\forall\alpha\in I)\; x\in A_\alpha\}
  \]
  and
  \[
    \bigcup_{\alpha\in I}A_\alpha = \{x: (\exists\alpha\in I)\; x\in A_\alpha\}.
  \]
\end{notation}

\begin{defi}[Ordered pair]
  An \emph{ordered pair} $(a, b)$ is a pair of two objects in which order matters. Formally, $(a, b)$ is defined as the set $\{\{a\}, \{a, b\}\}$.
\end{defi}

\begin{prop}
  Let $a, a', b, b'$ be objects. Then $(a, b) = (a', b')$ if and only if $a = a'$ and $b = b'$.
\end{prop}
\begin{proof}
  If $a = a'$ and $b = b'$, then clearly $\{\{a\},\{a,b\}\} = \{\{a'\},\{a',b'\}\}$.

  Conversely, suppose $\{\{a\},\{a,b\}\} = \{\{a'\},\{a',b'\}\}$. Then $\{a\} \in \{\{a'\},\{a',b'\}\}$, so $\{a\} = \{a'\}$ or $\{a\} = \{a',b'\}$. In either case, $a = a'$. It then follows that $\{a,b\} = \{a,b'\}$, so $b = b'$.
\end{proof}

\begin{defi}[Cartesian product]
  Let $A$ and $B$ be sets. The \emph{Cartesian product} of $A$ and $B$ is
  \[
    A\times B = \{(a, b) : a\in A,\; b\in B\}.
  \]
  More generally, for sets $A_1, \ldots, A_n$, we define $A_1 \times \cdots \times A_n$ inductively by $A_1 \times \cdots \times A_n = (A_1 \times \cdots \times A_{n-1}) \times A_n$.
\end{defi}

\begin{eg}
  $\R^3 = \R\times\R\times\R = \{(x,y,z): x, y, z\in \R\}$.
\end{eg}

\subsection{Functions}
\begin{defi}[Function/map]
  Let $A$ and $B$ be sets. A \emph{function} (or \emph{map}) $f: A\to B$ is a rule that assigns to each element $a\in A$ precisely one element $f(a)\in B$. We write $a\mapsto f(a)$. The set $A$ is called the \emph{domain} and $B$ the \emph{codomain} of $f$.
\end{defi}

\begin{remark}
  Formally, a function $f: A \to B$ can be defined as a subset $f\subseteq A\times B$ such that for every $a\in A$, there exists a unique $b\in B$ with $(a, b)\in f$. We then interpret $(a, b) \in f$ as $f(a) = b$. While this is rigorous, it is usually better to think of a function as a rule or assignment.
\end{remark}

\begin{eg}\leavevmode
  \begin{enumerate}
    \item The rule $f: \R \to \R$ defined by $f(x) = x^2$ is a function.
    \item The rule $g: \R \to \R$ defined by $g(x) = 1/x$ is \emph{not} a function, since $g(0)$ is not defined.
    \item The rule $h: \R \to \R$ defined by $h(x) = \pm\sqrt{x}$ is \emph{not} a function, since it is multi-valued.
  \end{enumerate}
\end{eg}

\begin{defi}[Injective function]
  A function $f: A \to B$ is \emph{injective} (or \emph{one-to-one}) if distinct elements of $A$ are mapped to distinct elements of $B$:
  \[
    (\forall x, y\in A)\;f(x) = f(y)\Rightarrow x = y.
  \]
\end{defi}

\begin{defi}[Surjective function]
  A function $f: A \to B$ is \emph{surjective} (or \emph{onto}) if every element of $B$ is in the image of $f$:
  \[
    (\forall b\in B)(\exists a\in A)\;f(a) = b.
  \]
\end{defi}

\begin{eg}
  The function $f: \R \to\R^+\cup\{0\}$ defined by $f(x) = x^2$ is surjective but not injective.
\end{eg}

\begin{defi}[Bijective function]
  A function $f: A \to B$ is \emph{bijective} if it is both injective and surjective, i.e.\ every element of $B$ is hit exactly once.
\end{defi}

\begin{defi}[Permutation]
  Let $A$ be a set. A \emph{permutation} of $A$ is a bijection $A\to A$.
\end{defi}

\begin{defi}[Composition of functions]
  Let $f: A \to B$ and $g: B\to C$ be functions. The \emph{composition} of $g$ with $f$ is the function $g\circ f: A \to C$ defined by $(g\circ f)(a) = g(f(a))$ for all $a \in A$.
\end{defi}

\begin{prop}
  Let $f: A \to B$, $g: B \to C$ and $h: C \to D$ be functions. Then $h \circ (g \circ f) = (h \circ g) \circ f$.
\end{prop}
\begin{proof}
  For every $a \in A$, we have $(h \circ (g \circ f))(a) = h(g(f(a))) = ((h \circ g) \circ f)(a)$.
\end{proof}

\begin{defi}[Image]
  Let $f: A\to B$ be a function and let $U\subseteq A$. The \emph{image} of $U$ under $f$ is the set $f(U) = \{f(u) : u\in U\}$. The \emph{image} of $f$ is the set $f(A) = \{f(a) : a \in A\}$.
\end{defi}

\begin{remark}
  By definition, $f$ is surjective if and only if $f(A) = B$.
\end{remark}

\begin{defi}[Pre-image]
  Let $f: A\to B$ be a function and let $V\subseteq B$. The \emph{pre-image} of $V$ under $f$ is the set $f^{-1}(V) = \{a\in A: f(a)\in V\}$.
\end{defi}

\begin{warning}
  The pre-image $f^{-1}(V)$ is defined for any function $f$ and any subset $V \subseteq B$. The same notation $f^{-1}$ is also used for the inverse function (defined below), which exists only when $f$ is bijective. These are distinct concepts despite sharing notation.
\end{warning}

\begin{defi}[Identity map]
  Let $A$ be a set. The \emph{identity map} $\id_A: A\to A$ is defined by $\id_A(a) = a$ for all $a \in A$.
\end{defi}

\begin{defi}[Left and right inverses]
  Let $f: A\to B$ be a function.
  \begin{itemize}
    \item A \emph{left inverse} of $f$ is a function $g: B\to A$ such that $g\circ f = \id_A$.
    \item A \emph{right inverse} of $f$ is a function $g: B\to A$ such that $f\circ g = \id_B$.
  \end{itemize}
\end{defi}

\begin{prop}
  Let $f: A \to B$ be a function. Then $f$ has a left inverse if and only if $f$ is injective.
\end{prop}
\begin{proof}
  ($\Rightarrow$) Suppose $g: B \to A$ is a left inverse of $f$. If $f(a) = f(a')$ for some $a, a' \in A$, then $a = g(f(a)) = g(f(a')) = a'$. Hence $f$ is injective.

  ($\Leftarrow$) Suppose $f$ is injective. Fix any element $a_0 \in A$ and define $g: B \to A$ by
  \[
    g(b) = \begin{cases}
      a &\text{if } b \in f(A), \text{ where } a \in A \text{ is the unique element with } f(a) = b,\\
      a_0 & \text{if } b \notin f(A).
    \end{cases}
  \]
  Then $g(f(a)) = a$ for all $a \in A$, so $g$ is a left inverse of $f$.
\end{proof}

\begin{prop}
  Let $f: A \to B$ be a function. Then $f$ has a right inverse if and only if $f$ is surjective.
\end{prop}
\begin{proof}
  ($\Rightarrow$) Suppose $g: B \to A$ is a right inverse of $f$. Then for every $b \in B$, we have $f(g(b)) = b$, so $b \in f(A)$. Hence $f$ is surjective.

  ($\Leftarrow$) Suppose $f$ is surjective. For each $b\in B$, choose some $a\in A$ with $f(a) = b$, and define $g(b) = a$. Then $f(g(b)) = b$ for all $b \in B$, so $g$ is a right inverse of $f$.
\end{proof}

\begin{remark}[Axiom of Choice]
  The reverse direction of the preceding proposition requires, for each $b \in B$, a \emph{choice} of an element $a \in A$ with $f(a) = b$. When $B$ is infinite, this involves infinitely many arbitrary choices. The \emph{Axiom of Choice} asserts that this is permitted: given a family of non-empty sets $(A_i)_{i \in I}$, there exists a \emph{choice function} $c: I \to \bigcup_{i \in I} A_i$ with $c(i) \in A_i$ for all $i \in I$.

  In fact, the existence of right inverses for surjections is \emph{equivalent} to the Axiom of Choice. To see this, suppose every surjection has a right inverse, and let $(A_i)_{i \in I}$ be a family of pairwise disjoint non-empty sets. Define $f: \bigcup_{i \in I} A_i \to I$ by sending each element to the index of the set containing it. Then $f$ is surjective, so it has a right inverse $g: I \to \bigcup_{i \in I} A_i$. This $g$ is a choice function for the family $(A_i)_{i \in I}$.
\end{remark}

\begin{defi}[Inverse of function]
  Let $f: A \to B$ be a function. An \emph{inverse} of $f$ is a function $g: B\to A$ that is both a left inverse and a right inverse of $f$, i.e.\ $g \circ f = \id_A$ and $f \circ g = \id_B$. When it exists, we write it as $f^{-1}: B\to A$.
\end{defi}

\begin{prop}
  Let $f: A \to B$ be a function. Then $f$ has an inverse if and only if $f$ is bijective. Moreover, if the inverse exists, it is unique.
\end{prop}
\begin{proof}
  If $f$ has an inverse, then $f$ has both a left inverse and a right inverse, so $f$ is both injective and surjective, i.e.\ bijective.

  Conversely, if $f$ is bijective, then for each $b \in B$ there exists a unique $a \in A$ with $f(a) = b$. Define $g(b) = a$. Then $g \circ f = \id_A$ and $f \circ g = \id_B$, so $g$ is an inverse of $f$.

  For uniqueness, suppose $g$ and $g'$ are both inverses of $f$. Then $g = g \circ \id_B = g \circ (f \circ g') = (g \circ f) \circ g' = \id_A \circ g' = g'$.
\end{proof}

\subsection{Relations}
\begin{defi}[Relation]
  Let $A$ be a set. A \emph{relation} $R$ on $A$ is a subset $R\subseteq A\times A$. We write $aRb$ if and only if $(a, b)\in R$.
\end{defi}

\begin{eg}
  The following are relations on the natural numbers:
  \begin{enumerate}
    \item $aRb$ iff $a$ and $b$ have the same final digit, e.g.\ $37R57$.
    \item $aRb$ iff $a$ divides $b$, e.g.\ $2R6$ and $2\not \!\!R 7$.
    \item $aRb$ iff $a\not= b$.
    \item $aRb$ iff $a = b = 1$.
    \item $aRb$ iff $|a - b|\leq 3$.
    \item $aRb$ iff either $a, b\geq 5$ or $a, b\leq 4$.
  \end{enumerate}
\end{eg}

\begin{defi}[Reflexive relation]
  A relation $R$ on $A$ is \emph{reflexive} if
  \[
    (\forall a \in A)\;aRa.
  \]
\end{defi}

\begin{defi}[Symmetric relation]
  A relation $R$ on $A$ is \emph{symmetric} if
  \[
    (\forall a, b \in A)\;aRb \Rightarrow bRa.
  \]
\end{defi}

\begin{defi}[Transitive relation]
  A relation $R$ on $A$ is \emph{transitive} if
  \[
    (\forall a, b, c \in A)\;aRb\wedge bRc \Rightarrow aRc.
  \]
\end{defi}

\begin{eg}
  We can classify the examples above as follows.
  \begin{center}
    \begin{tabular}{lcccccc}
      \toprule
      & (i) & (ii) & (iii) & (iv) & (v) & (vi) \\
      \midrule
      Reflexive & \checkmark & \checkmark & $\times$ & $\times$ & \checkmark & \checkmark \\
      Symmetric & \checkmark & $\times$ & \checkmark & \checkmark & \checkmark & \checkmark \\
      Transitive & \checkmark & \checkmark & $\times$ & \checkmark & $\times$ & \checkmark \\
      \bottomrule
    \end{tabular}
  \end{center}
\end{eg}

\begin{defi}[Equivalence relation]
  A relation on $A$ is an \emph{equivalence relation} if it is reflexive, symmetric and transitive.
\end{defi}

\begin{eg}
  In the examples above, (i) and (vi) are equivalence relations.
\end{eg}

\begin{remark}
  If $\sim$ is an equivalence relation, we think of $a \sim b$ as saying that $a$ and $b$ are ``essentially the same''. For instance, on $\Z \times (\Z \setminus \{0\})$, we can define $(n, m) \sim (p, q)$ iff $nq = mp$. Two pairs are equivalent precisely when they represent the same rational number.
\end{remark}

\begin{eg}
  Consider a deck of cards. Define a relation $\sim$ by declaring two cards equivalent if they have the same suit. This is an equivalence relation.
\end{eg}

\begin{defi}[Equivalence class]
  Let $\sim$ be an equivalence relation on $A$. The \emph{equivalence class} of $x \in A$ is the set
  \[
    [x] = \{a \in A : a \sim x\}.
  \]
\end{defi}

\begin{eg}
  In the cards example, $[8\heartsuit]$ is the set of all hearts.
\end{eg}

\begin{defi}[Partition]
  A \emph{partition} of a set $A$ is a collection of non-empty subsets $(A_i)_{i \in I}$ of $A$ such that every element of $A$ belongs to exactly one $A_i$. Equivalently, the sets $A_i$ are pairwise disjoint and $\bigcup_{i \in I} A_i = A$.
\end{defi}

\begin{prop}
  Let $\sim$ be an equivalence relation on $A$. Then the equivalence classes of $\sim$ form a partition of $A$.
\end{prop}

\begin{proof}
  Each equivalence class is non-empty: by reflexivity, $a \in [a]$ for every $a \in A$. Moreover, every element of $A$ belongs to at least one equivalence class. It remains to show that any two equivalence classes are either equal or disjoint.

  Suppose $[a]\cap[b]\not=\emptyset$, so there exists $c \in [a]\cap[b]$. Then $a\sim c$ and $b\sim c$. By symmetry, $c\sim b$, and by transitivity, $a\sim b$. Now for any $b'\in [b]$, we have $b\sim b'$, so by transitivity $a\sim b'$, giving $b' \in [a]$. Hence $[b]\subseteq[a]$. By a symmetric argument, $[a]\subseteq[b]$, so $[a] = [b]$.
\end{proof}

\begin{prop}
  Conversely, every partition of $A$ determines an equivalence relation on $A$, by declaring $a \sim b$ if and only if $a$ and $b$ belong to the same part.
\end{prop}
\begin{proof}
  Reflexivity, symmetry and transitivity follow immediately from the definition.
\end{proof}

\begin{defi}[Quotient map]
  Let $\sim$ be an equivalence relation on $A$. The \emph{quotient map} is the function $q: A \to A/{\sim}$ defined by $q(a) = [a]$, where $A/{\sim} = \{[a] : a \in A\}$ denotes the set of equivalence classes.
\end{defi}

\begin{eg}
  In the cards example, $q(8\heartsuit) = \{\text{all hearts}\}$.
\end{eg}

\section{Division}
\subsection{Euclid's Algorithm}
\begin{defi}[Divisibility]
  Let $a, b\in \Z$. We say $a$ \emph{divides} $b$, or $a$ is a \emph{factor} of $b$, written $a\mid b$, if there exists $c\in \Z$ such that $b = ac$.
\end{defi}

\begin{remark}
  For any $b \in \Z$, the integers $\pm 1$ and $\pm b$ always divide $b$. These are the \emph{trivial factors}. Any other factor is called a \emph{proper factor}.
\end{remark}

\begin{thm}[Division Algorithm]
  Let $a\in \Z$ and $b\in \Z$ with $b > 0$. Then there exist unique $q, r\in \Z$ with $a = qb + r$ and $0\leq r < b$.
\end{thm}

\begin{remark}
  Despite the name, the division algorithm is not an algorithm in the usual sense. It merely asserts the existence and uniqueness of the quotient $q$ and remainder $r$.
\end{remark}

\begin{proof}
  Let $q = \max\{n \in \Z : nb \leq a\}$. This set is non-empty and bounded above, so the maximum exists. Set $r = a - qb$. By definition of $q$, we have $qb \leq a < (q+1)b$, so $0\leq r < b$.

  For uniqueness, suppose $a = qb + r = q'b + r'$ with $0 \leq r, r' < b$. Then $(q - q')b = r' - r$. Since $-b < r' - r < b$ and $r' - r$ is a multiple of $b$, we must have $r' - r = 0$, so $q = q'$ and $r = r'$.
\end{proof}

\begin{defi}[Common factor]
  A \emph{common factor} of $a, b \in \Z$ is an integer $c$ such that $c\mid a$ and $c\mid b$.
\end{defi}

\begin{defi}[Highest common factor]
  Let $a, b\in \N$. The \emph{highest common factor} (or \emph{greatest common divisor}) of $a$ and $b$ is a natural number $d$ such that:
  \begin{enumerate}
    \item $d$ is a common factor of $a$ and $b$, and
    \item every common factor $c$ of $a$ and $b$ satisfies $c\mid d$.
  \end{enumerate}
\end{defi}

\begin{remark}
  If the highest common factor $d$ exists, it is necessarily the largest common factor of $a$ and $b$, since every common factor divides $d$. In particular, it is unique.
\end{remark}

\begin{remark}
  One might instead define $\hcf(a, b)$ as the largest common factor, and then prove that all common factors divide it. The definition above is preferable because it does not require a prior ordering, and generalises to arbitrary rings (see IB Groups, Rings and Modules).
\end{remark}

\begin{notation}
  We write $\hcf(a, b) = \gcd(a, b) = (a, b)$ for the highest common factor. The notation $(a, b)$ should not be confused with the ordered pair.
\end{notation}

\begin{prop}
  If $c\mid a$ and $c\mid b$, then $c\mid (ua + vb)$ for all $u, v\in \Z$.
\end{prop}

\begin{proof}
  Write $a = kc$ and $b = lc$. Then $ua + vb = ukc + vlc = (uk + vl)c$, so $c\mid (ua + vb)$.
\end{proof}

\begin{thm}
  Let $a, b\in \N$. Then $(a, b)$ exists.
\end{thm}

\begin{proof}
  Let $S=\{ua + vb : u, v\in\Z\}$ be the set of all integer linear combinations of $a$ and $b$. Let $d$ be the smallest positive element of $S$, say $d = xa + yb$. If $c\mid a$ and $c\mid b$, then $c\mid d$ by the preceding proposition, so condition (ii) is satisfied. It remains to show that $d\mid a$ and $d\mid b$.

  By the division algorithm, write $a = qd + r$ with $0\leq r < d$. Then $r = a - qd = a(1 - qx) - qyb \in S$. Since $d$ is the smallest positive element of $S$ and $0\leq r < d$, we must have $r = 0$, so $d\mid a$. Similarly, $d\mid b$.
\end{proof}

\begin{cor}
  Let $d = (a, b)$. Then $d$ is the smallest positive integer linear combination of $a$ and $b$.
\end{cor}

\begin{cor}[B\'{e}zout's identity]
  Let $a, b\in\N$ and $c\in \Z$. Then there exist $u, v\in \Z$ with $c=ua + vb$ if and only if $(a, b)\mid c$.
\end{cor}

\begin{proof}
  ($\Rightarrow$) Let $d=(a, b)$. Since $d\mid a$ and $d\mid b$, we have $d\mid (ua + vb) = c$.

  ($\Leftarrow$) Suppose $d\mid c$. Write $d = xa + yb$ and $c = kd$. Then $c = (kx)a + (ky)b$.
\end{proof}

\begin{remark}
  The proof that $(a, b)$ exists is non-constructive: it shows that $d$ exists but does not provide an efficient method for computing it. Euclid's algorithm, given below, provides such a method.
\end{remark}

The key observation is that for any $q \in \Z$, the integers $a$ and $b$ have the same set of common factors as $b$ and $a - qb$. In particular, $(a, b) = (b, a - qb)$.

\begin{prop}[Euclid's Algorithm]
  Let $a, b \in \N$ with $b > 0$. Apply the division algorithm repeatedly:
  \begin{align*}
    a &= q_1b + r_1\\
    b &= q_2r_1 + r_2\\
    r_1 &= q_3r_2 + r_3\\
    &\;\;\vdots\\
    r_{n-2} &= q_nr_{n-1}.
  \end{align*}
  This process terminates since $b > r_1 > r_2 > \cdots \geq 0$. Then $\hcf(a, b) = r_{n-1}$, the last non-zero remainder.
\end{prop}

\begin{proof}
  At each step, the set of common factors is preserved:
  \[
    \{\text{common factors of } a, b\} = \{\text{common factors of } b, r_1\} = \cdots = \{\text{factors of } r_{n-1}\}.
  \]
  In particular, $r_{n-1}$ is a common factor of $a$ and $b$, and every common factor of $a$ and $b$ divides $r_{n-1}$, so $r_{n-1} = (a, b)$.
\end{proof}

\begin{remark}
  This gives an alternative proof that highest common factors exist. Moreover, the algorithm is efficient: since $a \geq b + r_1 > 2r_1$, the remainders decrease by at least half every two steps. Hence the number of digits decreases at a constant rate, and the algorithm terminates in $O(\log b)$ steps.
\end{remark}

\begin{eg}
  Let $a = 57$ and $b = 42$.
  \begin{center}
    \begin{tabular}{l l l}
      common factors of $57$ and $42$ & & $57 = 1\times 42 + 15$ \\
      = common factors of $42$ and $15$ & & $42 = 2\times 15 + 12$ \\
      = common factors of $15$ and $12$ & & $15 = 1\times 12 + 3$ \\
      = common factors of $12$ and $3$ & & $12 = 4\times 3 + 0$ \\
      = common factors of $3$ and $0$ \\
      = factors of $3$.
    \end{tabular}
  \end{center}
  So $\hcf(57, 42) = 3$.
\end{eg}

By reversing the steps of Euclid's algorithm, we can express $(a, b)$ as a linear combination of $a$ and $b$.
\begin{eg}
  Consider $a = 57$ and $b = 21$.
  \begin{align*}
    57 &= 2\times 21 + 15\\
    21 &= 1\times 15 + 6\\
    15 &= 2\times 6 + 3\\
    6 &= 2\times 3
  \end{align*}
  Reversing:
  \begin{align*}
    3 &= 15 - 2\times 6\\
    &= 15 - 2\times (21 - 15)\\
    &= 3\times 15 - 2\times 21\\
    &= 3\times (57 - 2\times 21) - 2\times 21\\
    &= 3\times 57 - 8\times 21.
  \end{align*}
\end{eg}

\begin{remark}
  This back-substitution gives a constructive proof of B\'{e}zout's identity and a method for expressing $(a, b) = xa + yb$. However, it requires storing all intermediate steps and is therefore not space-efficient.
\end{remark}

To achieve higher space efficiency, we seek a recurrence relation for coefficients $A_j, B_j$ satisfying $a B_j - b A_j = (-1)^{j}r_j$, where the sign factor $(-1)^j$ is introduced to simplify the recurrence.

\begin{prop}
  The coefficients $A_j, B_j$ satisfy the recurrence
  \begin{align*}
    A_j &= q_jA_{j-1} + A_{j-2},\\
    B_j &= q_jB_{j-1} + B_{j-2},
  \end{align*}
  with $a B_j - b A_j = (-1)^{j}r_j$.
  In particular, $|a B_{n-1} - b A_{n-1}| = r_{n - 1} = (a, b)$.
\end{prop}

\begin{proof}
  Suppose the identity $a B_i - b A_i = (-1)^i r_i$ holds for all $i < j$. Then
  \begin{align*}
    (-1)^jr_{j} &= (-1)^j(r_{j - 2} - q_jr_{j - 1})\\
    &= (-1)^{j - 2} r_{j - 2} + q_j (-1)^{j - 1} r_{j - 1}\\
    &= a (B_{j - 2} + q_j B_{j - 1}) - b (A_{j - 2} + q_j A_{j - 1}).
  \end{align*}
  Setting $A_j = q_j A_{j-1} + A_{j-2}$ and $B_j = q_j B_{j-1} + B_{j-2}$ gives $a B_j - b A_j = (-1)^j r_j$.
\end{proof}

\begin{remark}
  By an easy induction, $A_jB_{j - 1} - B_jA_{j-1} = (-1)^j$, so in particular $(A_j, B_j) = 1$.
\end{remark}

\begin{remark}[Continued fractions]
  Euclid's algorithm can be expressed in terms of continued fractions. For example, with $a = 57$ and $b = 21$:
  \[
    \frac{57}{21} = 2 + \cfrac{1}{1 + \cfrac{1}{2 + \cfrac{1}{2}}}.
  \]
  The successive \emph{convergents} obtained by truncating this expansion are $2$, $2 + \frac{1}{1} = 3$, $2 + \frac{1}{1 + \frac{1}{2}} = \frac{8}{3}$. These are precisely the ratios $\frac{A_j}{B_j}$.
\end{remark}

\subsection{Primes}
\begin{defi}[Prime number]
  A natural number $p$ is \emph{prime} if $p > 1$ and the only factors of $p$ in $\Z$ are $\pm 1$ and $\pm p$.
\end{defi}

\begin{prop}
  Every natural number $n \geq 2$ can be written as a product of primes.
\end{prop}

\begin{proof}
  If $n$ is prime, we are done. Otherwise, $n = ab$ where $1 < a, b < n$. If either factor is not prime, we factor it further. Since the factors are strictly decreasing, the process terminates with all factors prime.
\end{proof}

\begin{remark}
  The phrase ``and the process terminates'' is justified rigorously by the principle of strong induction, which we will establish later.
\end{remark}

\begin{thm}
  There are infinitely many primes.
\end{thm}

\begin{proof}[Proof (Euclid)]
  Suppose there are finitely many primes, say $p_1, p_2, \ldots, p_n$. Consider $N = p_1 p_2 \cdots p_n + 1$. Then $N$ is not divisible by any $p_j$, since $p_j \mid N$ would imply $p_j \mid (N - p_1 p_2 \cdots p_n) = 1$, which is impossible. But $N \geq 2$, so $N$ has a prime factor, which must lie outside the list $p_1, \ldots, p_n$. Contradiction.
\end{proof}

\begin{proof}[Proof (Erd\"{o}s)]
  Suppose there are finitely many primes, $p_1, p_2, \ldots, p_k$. Every natural number can be written as $p_1^{j_1} p_2^{j_2} \cdots p_k^{j_k}$ for some $j_i \geq 0$. Factoring out the largest square, we can write any such number in the form $m^2 p_1^{i_1} p_2^{i_2} \cdots p_k^{i_k}$, where $m \in \N$ and each $i_j \in \{0, 1\}$.

  For any $N \in \N$, each number $x \leq N$ in this form satisfies $m \leq \sqrt{N}$, so there are at most $\sqrt{N}$ choices for $m$ and $2^k$ choices for the exponents $i_j$. Hence there are at most $\sqrt{N} \cdot 2^k$ numbers of this form up to $N$.

  Choosing $N \geq 4^k$ gives $N > \sqrt{N} \cdot 2^k$, so some number $\leq N$ cannot be written in this form. Contradiction.
\end{proof}

\begin{remark}
  The two proofs are structurally different. Euclid's proof exhibits a \emph{particular} number $N$ and shows that \emph{all} its prime factors lie outside the given list. Erd\"{o}s' proof shows that \emph{some} number (which we do not identify) must have \emph{at least one} prime factor outside the list. The proofs also give different bounds: Euclid's argument shows the $k$th prime is at most $2^{2^k}$, while Erd\"{o}s' gives the bound $4^k$.
\end{remark}

\begin{defi}[Coprime integers]
  Two integers $a, b$ are \emph{coprime} if $(a, b) = 1$.
\end{defi}

\begin{prop}
  If $a\mid bc$ and $a$ is coprime to $b$, then $a \mid c$.
\end{prop}

\begin{proof}
  By B\'{e}zout's identity, there exist $u, v\in \Z$ such that $ua + vb = 1$. Multiplying by $c$ gives $uac + vbc = c$. Since $a \mid uac$ and $a \mid vbc$ (as $a \mid bc$), we have $a \mid c$.
\end{proof}

\begin{cor}[Euclid's lemma]
  If $p$ is prime and $p\mid ab$, then $p\mid a$ or $p\mid b$.
\end{cor}

\begin{proof}
  Since $p$ is prime, $(p, a) = p$ or $(p, a) = 1$. In the first case, $p \mid a$. In the second, $p$ and $a$ are coprime, so $p \mid b$ by the preceding proposition.
\end{proof}

\begin{cor}
  If $p$ is prime and $p\mid n_1 n_2 \cdots n_k$, then $p \mid n_j$ for some $j$.
\end{cor}

\begin{remark}
  The definition of primality concerns the factors \emph{of} $p$. The corollaries above give a complementary characterisation: they describe how $p$ behaves as a factor \emph{of other numbers}.
\end{remark}

\begin{thm}[Fundamental Theorem of Arithmetic]
  Every natural number $n \geq 2$ can be expressed as a product of primes in exactly one way. More precisely, if $p_1 p_2 \cdots p_k = q_1 q_2 \cdots q_l$, where the $p_i$ and $q_j$ are primes (not necessarily distinct), then $k = l$ and, after reordering, $q_j = p_j$ for all $j$.
\end{thm}

\begin{proof}
  Existence was shown above. For uniqueness, suppose $p_1 \cdots p_k = q_1 \cdots q_l$. Since $p_1 \mid q_1 \cdots q_l$, Euclid's lemma gives $p_1 \mid q_j$ for some $j$. Since $q_j$ is prime, $p_1 = q_j$. Reordering, we may assume $p_1 = q_1$. Cancelling gives $p_2 \cdots p_k = q_2 \cdots q_l$. Repeating this argument (formally, by strong induction) yields $k = l$ and $p_j = q_j$ for all $j$.
\end{proof}

\begin{cor}
  Let $p_1, \ldots, p_r$ be distinct primes and write $a = p_1^{i_1} p_2^{i_2} \cdots p_r^{i_r}$ and $b = p_1^{j_1} p_2^{j_2} \cdots p_r^{j_r}$, where the exponents are non-negative integers. Then
  \[
    (a, b) = \prod_{k=1}^{r} p_k^{\min\{i_k, j_k\}}, \qquad \lcm(a, b) = \prod_{k=1}^{r} p_k^{\max\{i_k, j_k\}}.
  \]
  In particular, $\hcf(a, b) \cdot \lcm(a, b) = ab$.
\end{cor}

\begin{remark}
  While this gives a clean formula, it is not an efficient method for computing $(a, b)$ in practice, since prime factorisation is computationally hard. Euclid's algorithm is far more efficient.
\end{remark}

\begin{remark}
  Unique factorisation is a special property of $\Z$. There exist other algebraic systems admitting addition, multiplication and subtraction where factorisation is not unique.
\end{remark}

\begin{eg}
  The following systems do not have unique prime factorisation.
  \begin{enumerate}
    \item \emph{Even numbers.} In this system, the ``primes'' are the numbers $2p$ for odd primes $p$, together with $2$ itself. For instance, $6$ is prime (it is not divisible by $2$ in this system!) while $8 = 2 \times 4$ is not. We have $60 = 2\times 30 = 6\times 10$, where $2, 6, 10, 30$ are all prime. However, this system lacks a multiplicative identity, so it is not a ring.
    \item \emph{The ring $\Z[\sqrt{-5}] = \{a + b\sqrt{-5} : a, b\in \Z\}$.} We have $6 = 2\times 3 = (1 - \sqrt{-5})(1 + \sqrt{-5})$, and it can be shown that all four factors are prime (see IB Groups, Rings and Modules).
  \end{enumerate}
\end{eg}

\begin{exercise}
  Where does the proof of the Fundamental Theorem of Arithmetic fail in these examples?
\end{exercise}

\section{Counting and integers}
\subsection{Basic counting}
\begin{thm}[Pigeonhole Principle]
  If $mn + 1$ objects are placed into $n$ boxes, then some box contains at least $m + 1$ objects.
\end{thm}

\begin{eg}
  In Cambridge, there exist two people with the same number of hairs.
\end{eg}

\begin{defi}[Indicator function]
  Let $X$ be a set and let $A\subseteq X$. The \emph{indicator function} (or \emph{characteristic function}) of $A$ is the function $i_A: X\to \{0, 1\}$ defined by
  \[
    i_A(x) = \begin{cases} 1 & \text{if } x \in A, \\ 0 & \text{if } x \notin A. \end{cases}
  \]
  It is sometimes written $\chi_A$.
\end{defi}

\begin{prop}\leavevmode
  \begin{enumerate}
    \item $i_A = i_B \Leftrightarrow A = B$.
    \item $i_{A\cap B} = i_A i_B$.
    \item $i_{\bar{A}} = 1 - i_A$.
    \item $i_{A\cup B} = i_A + i_B - i_{A\cap B}$.
    \item $i_{A\setminus B} = i_A - i_{A\cap B}$.
  \end{enumerate}
\end{prop}

\begin{proof}
  Parts (i)--(iii) follow directly from the definition. For (iv):
  \[
    i_{A\cup B} = 1 - i_{\overline{A\cup B}} = 1 - i_{\bar A \cap \bar B} = 1 - (1 - i_A)(1 - i_B) = i_A + i_B - i_A i_B = i_A + i_B - i_{A \cap B}.
  \]
  Part (v) follows similarly: $i_{A\setminus B} = i_{A\cap \bar B} = i_A(1 - i_B) = i_A - i_{A\cap B}$.
\end{proof}

\begin{eg}
  Indicator functions give algebraic proofs of set identities.
  \begin{enumerate}
    \item \emph{Distributivity: $A\cap(B\cup C) = (A\cap B)\cup (A\cap C)$.} Since $i_A^2 = i_A$ (as $i_A$ takes values in $\{0,1\}$), we have
      \begin{align*}
        i_{A\cap (B\cup C)} &= i_A(i_B + i_C - i_Bi_C) = i_Ai_B + i_Ai_C - i_Ai_Bi_C,\\
        i_{(A\cap B)\cup (A\cap C)} &= i_Ai_B + i_Ai_C - i_Ai_B \cdot i_Ai_C = i_Ai_B + i_Ai_C - i_A^2 i_Bi_C.
      \end{align*}
      Since $i_A^2 = i_A$, both expressions agree, so $A\cap(B\cup C) = (A\cap B)\cup (A\cap C)$.
    \item \emph{Associativity of symmetric difference.} Observe that $i_{A\Delta B} \equiv i_A + i_B \pmod 2$. Thus $i_{(A\Delta B)\Delta C} \equiv i_A + i_B + i_C \equiv i_{A\Delta(B\Delta C)} \pmod 2$.
  \end{enumerate}
\end{eg}

\begin{remark}
  If $X$ is a finite set and $A\subseteq X$, then $|A| = \sum_{x\in X}i_A(x)$. This makes indicator functions a powerful tool for counting.
\end{remark}

\begin{prop}
  Let $A, B$ be subsets of a finite set $X$. Then $|A\cup B| = |A| + |B| - |A\cap B|$.
\end{prop}

\begin{proof}
  \begin{align*}
    |A\cup B| &= \sum_{x\in X} i_{A\cup B}(x)\\
    &= \sum_{x \in X} (i_A(x) + i_B(x) - i_{A\cap B}(x))\\
    &= \sum_{x \in X} i_A(x) + \sum_{x \in X} i_B(x) - \sum_{x \in X} i_{A\cap B}(x)\\
    &= |A| + |B| - |A\cap B|.\qedhere
  \end{align*}
\end{proof}

\begin{thm}[Inclusion-Exclusion Principle]
  Let $A_1, \ldots, A_n$ be subsets of a finite set $X$. Then
  \[
    |\bar A_1\cap \cdots \cap \bar A_n| = |X| - \sum_i |A_i| + \sum_{i < j}|A_i\cap A_j| - \cdots + (-1)^n|A_1\cap \cdots \cap A_n|.
  \]
  Equivalently,
  \[
    |A_1\cup \cdots \cup A_n| = \sum_i|A_i| - \sum_{i < j}|A_i\cap A_j| + \cdots +(-1)^{n-1}|A_1\cap \cdots \cap A_n|.
  \]
\end{thm}

\begin{remark}
  The two forms are equivalent since $|A_1\cup\cdots\cup A_n| = |X| - |\bar A_1\cap \cdots \cap \bar A_n|$.
\end{remark}

\begin{proof}
  Using indicator functions,
  \begin{align*}
    i_{\bar A_1\cap \bar A_2\cap \cdots \cap \bar A_n} &= \prod_j i_{\bar A_j}\\
    &= \prod_j (1 - i_{A_j})\\
    &= 1 - \sum_i i_{A_i} + \sum _{i < j}i_{A_i}i_{A_j} - \cdots + (-1)^ni_{A_1}i_{A_2}\cdots i_{A_n}\\
    &= 1 - \sum_i i_{A_i} + \sum_{i < j}i_{A_i\cap A_j} - \cdots + (-1)^ni_{A_1\cap A_2\cap \cdots \cap A_n}.
    \intertext{Summing over $x \in X$:}
    |\bar A_1\cap \cdots \cap \bar A_n| &= \sum_{x\in X} i_{\bar A_1\cap \bar A_2\cap \cdots \cap \bar A_n}(x)\\
    &= |X| - \sum_i |A_i| + \sum_{i < j}|A_i\cap A_j|\\
    & - \sum_{i < j < k}|A_i\cap A_j\cap A_k| + \cdots + (-1)^n|A_1\cap A_2\cap \cdots \cap A_n|.\qedhere
  \end{align*}
\end{proof}

\begin{eg}
  How many integers in $\{1, 2, \ldots, 200\}$ are coprime to $110$?

  Since $110 = 2 \times 5 \times 11$, let $X = \{1, \ldots, 200\}$ and define $A_1 = \{x \in X : 2 \mid x\}$, $A_2 = \{x \in X : 5\mid x\}$, $A_3 = \{x \in X : 11\mid x\}$. Then
  \begin{align*}
    |A_1| &= \lfloor 200/2\rfloor = 100, &
    |A_1\cap A_2| &= \lfloor 200/10\rfloor = 20,\\
    |A_2| &= \lfloor 200/5\rfloor = 40, &
    |A_1\cap A_3| &= \lfloor 200/22\rfloor = 9,\\
    |A_3| &= \lfloor 200/11\rfloor = 18, &
    |A_2\cap A_3| &= \lfloor 200/55\rfloor = 3,\\
    && |A_1 \cap A_2\cap A_3| &= \lfloor 200/110\rfloor = 1.
  \end{align*}
  By inclusion-exclusion, $|\bar A_1 \cap \bar A_2 \cap \bar A_3| = 200 - 100 - 40 - 18 + 20 + 9 + 3 - 1 = 73$.
\end{eg}

\subsection{Combinations}
\begin{eg}
  How many subsets of $\{1, 2, \ldots, n\}$ are there? Each element is either in or out, giving $2$ independent choices per element, so the answer is $2^n$. Equivalently, there are $2^n$ indicator functions $\{1, 2, \ldots, n\} \to \{0, 1\}$.
\end{eg}

\begin{defi}[Binomial coefficient]
  The number of subsets of $\{1, 2, \ldots, n\}$ of size $r$ is denoted $\binom{n}{r}$, pronounced ``$n$ choose $r$''.
\end{defi}

\begin{remark}
  This is a \emph{definition} of $\binom{n}{r}$, not a formula for computing it. A closed-form expression will be derived below.
\end{remark}

\begin{prop}
  $\displaystyle\sum_{r=0}^{n} \binom{n}{r} = 2^n$.
\end{prop}
\begin{proof}
  Both sides count the total number of subsets of $\{1, 2, \ldots, n\}$.
\end{proof}

\begin{thm}[Binomial theorem]
  Let $n\in \N$ and $a, b\in \R$. Then
  \[
    (a + b)^n = \sum_{r=0}^{n}\binom{n}{r}a^{n - r}b^r.
  \]
\end{thm}

\begin{proof}
  Expanding $(a + b)^n = (a + b)(a + b)\cdots (a + b)$, each term is obtained by choosing $b$ from some of the $n$ factors and $a$ from the rest. The term $a^{n - r}b^r$ arises from choosing $b$ in exactly $r$ of the $n$ factors, which can be done in $\binom{n}{r}$ ways.
\end{proof}

\begin{remark}
  The binomial theorem is not immediately useful for computation, since we do not yet have a formula for $\binom{n}{r}$.
\end{remark}

\begin{prop}[Symmetry]
  $\displaystyle\binom{n}{r} = \binom{n}{n - r}$.
\end{prop}
\begin{proof}
  Choosing $r$ elements to include is the same as choosing $n - r$ elements to exclude.
\end{proof}

\begin{prop}[Pascal's identity]
  $\displaystyle\binom{n}{r - 1} + \binom{n}{r} = \binom{n + 1}{r}$.
\end{prop}
\begin{proof}
  The right-hand side counts the subsets of size $r$ from $\{1, 2, \ldots, n+1\}$. Partition these into those containing $n+1$ (there are $\binom{n}{r-1}$, since we must choose the remaining $r - 1$ elements from $\{1, \ldots, n\}$) and those not containing $n+1$ (there are $\binom{n}{r}$).
\end{proof}

\begin{remark}
  Since $\binom{n}{0} = \binom{n}{n} = 1$, Pascal's identity allows us to construct \emph{Pascal's triangle}:
  \begin{center}
    \begin{tabular}{lllllllll}
      & & & & 1 & & & & \\
      & & & 1 & & 1 & & & \\
      & & 1 & & 2 & & 1 & & \\
      & 1 & & 3 & & 3 & & 1 & \\
      1 & & 4 & & 6 & & 4 & & 1 \\
    \end{tabular}
  \end{center}
  where each entry is the sum of the two entries above it, and the $r$th entry of the $n$th row (starting from row $0$) is $\binom{n}{r}$.
\end{remark}

\begin{prop}
  $\displaystyle\binom{n}{k}\binom{k}{r} = \binom{n}{r}\binom{n - r}{k - r}$.
\end{prop}
\begin{proof}
  Both sides count the number of pairs $(Y, Z)$ of subsets of $\{1, \ldots, n\}$ with $|Y| = k$, $|Z| = r$, and $Z\subseteq Y$. The left-hand side first chooses $Y$, then $Z \subseteq Y$. The right-hand side first chooses $Z$, then the remaining $k - r$ elements of $Y$ from $\{1, \ldots, n\}\setminus Z$.
\end{proof}

\begin{prop}[Vandermonde's identity]
  $\displaystyle\sum_{k=0}^{r} \binom{a}{k}\binom{b}{r - k} = \binom{a + b}{r}$.
\end{prop}
\begin{proof}
  The right-hand side counts the subsets of size $r$ from a set of $a + b$ elements. Partition this set into a group of $a$ and a group of $b$. If exactly $k$ elements are chosen from the first group, the remaining $r - k$ must come from the second, giving $\binom{a}{k}\binom{b}{r-k}$ choices. Summing over $k$ gives the result.
\end{proof}

\begin{eg}[Stars and bars]
  A greengrocer stocks $n$ kinds of fruit. In how many ways can we choose a bag of $r$ fruits, allowing repetition?

  Each selection can be encoded as a binary string of $r$ zeros and $n - 1$ ones, of total length $n + r - 1$: the zeros represent fruits and the ones act as dividers between types. For instance, with $n = 5$ and $r = 8$, the string $000100110010$ encodes $3$ of type 1, $1$ of type 2, $0$ of type 3, $2$ of type 4, and $2$ of type 5.

  The number of such strings is $\binom{n + r - 1}{r}$.
\end{eg}

\begin{prop}
  $\displaystyle\binom{n}{r} = \frac{n!}{(n - r)!\,r!}$.
\end{prop}

\begin{proof}
  There are $n(n - 1)\cdots (n - r + 1) = \frac{n!}{(n - r)!}$ ways to choose an ordered sequence of $r$ elements from $\{1, \ldots, n\}$. Each subset of size $r$ is counted $r!$ times (once per ordering), so $\binom{n}{r} = \frac{n!}{(n - r)!\,r!}$.
\end{proof}

\begin{defi}[Falling factorial]
  For $x \in \R$ and $r \in \N$, the \emph{falling factorial} is defined by $x^{\underline{r}} = x(x - 1)\cdots (x - r + 1)$.
\end{defi}

\begin{remark}
  With this notation, $\binom{n}{r} = \frac{n^{\underline{r}}}{r!}$. Multiplying Vandermonde's identity by $r!$ gives the \emph{falling factorial binomial theorem}:
  \[
    (a + b)^{\underline{r}} = \sum_{k=0}^{r}\binom{r}{k}\,a^{\underline{r - k}}\,b^{\underline{k}}.
  \]
\end{remark}

\begin{eg}[Derangements]
  A bank prepares a personalised letter for each of its $n$ customers and places them into envelopes. In how many ways can every letter end up in the wrong envelope?

  Let $X$ be the set of all permutations of $\{1, \ldots, n\}$, so $|X| = n!$. For each $i$, let $A_i = \{x \in X : x(i) = i\}$ be the set of permutations fixing customer $i$. We seek $|\bar A_1 \cap \cdots \cap \bar A_n|$, the number of \emph{derangements}.

  For any set $S \subseteq \{1, \ldots, n\}$ of size $s$, the number of permutations fixing every element of $S$ is $(n - s)!$. Hence $\sum_{|S|=s}|{\textstyle\bigcap_{i \in S}} A_i| = \binom{n}{s}(n-s)!$. By inclusion-exclusion:
  \begin{align*}
    \left|\bigcap_{i=1}^n \bar A_i\right| &= n! - \binom{n}{1}(n - 1)! + \binom{n}{2}(n - 2)! - \cdots + (-1)^n\binom{n}{n}\cdot 0!\\
    &= n!\left(1 - \frac{1}{1!} + \frac{1}{2!} - \cdots + \frac{(-1)^n}{n!}\right)\\
    &\approx \frac{n!}{e}.
  \end{align*}
\end{eg}
\subsection{Well-ordering and induction}
\begin{remark}
  Several proofs so far have relied on ``taking the least integer such that\ldots'' (e.g.\ the division algorithm) or on a sequence of steps that ``continues until\ldots'' (e.g.\ Euclid's algorithm, every number is a product of primes). The following principle makes such arguments rigorous.
\end{remark}

\begin{thm}[Weak Principle of Induction]
  Let $P(n)$ be a statement about the natural number $n$. Suppose that
  \begin{enumerate}
    \item $P(1)$ is true, and
    \item $(\forall n \in \N)\;P(n)\Rightarrow P(n + 1)$.
  \end{enumerate}
  Then $P(n)$ is true for all $n \in \N$.
\end{thm}


\begin{eg}[Tower of Hanoi]
  Consider the following setup.
  \begin{center}
    \usetikzlibrary{shapes}
    \definecolor{darkbrown}{rgb}{0.375,0.25,0.125}
    \tikzset{
      disc/.style={shade, shading=radial, rounded rectangle,minimum height=.5cm,
      inner color=#1!20, outer color=#1!60!gray},
      disc 1/.style={disc=yellow, minimum width=15mm},
      disc 2/.style={disc=orange, minimum width=20mm},
      disc 3/.style={disc=red, minimum width=25mm},
      disc 4/.style={disc=green, minimum width=33mm},
    }
    \begin{tikzpicture}
      \fill [darkbrown] (-0.125,2.5mm) rectangle (.125,3.5);
      \fill [darkbrown] (3.075,2.5mm) rectangle (3.325,3.5);
      \fill [darkbrown] (6.275,2.5mm) rectangle (6.525,3.5);

      \fill [darkbrown] (-1.6, 0) rectangle (8,0.25);

      \node[disc 4,yshift={5mm}] {$n$};
      \node[yshift={11mm}] {$\vdots$};
      \node[disc 3,yshift={15mm}] {3};
      \node[disc 2,yshift={20mm}] {2};
      \node[disc 1,yshift={25mm}] {1};

      \node at (0, -.25) {A};
      \node at (3.2, -.25) {B};
      \node at (6.4, -.25) {C};
    \end{tikzpicture}
  \end{center}
  The objective is to move $n$ rings from peg A to peg B, subject to the constraints that only one ring may be moved at a time, and a larger ring may never be placed on a smaller one.

  \emph{Claim:} this requires exactly $2^n - 1$ moves. Let $P(n)$ be the statement ``$n$ rings require exactly $2^n - 1$ moves''. This contains two assertions: (1) we can do it in $2^n - 1$ moves; (2) we cannot do it in fewer.

  \emph{Base case.} $P(1)$ is clear: one ring requires one move.

  \emph{Inductive step.} Suppose $P(n)$ holds. Given $n + 1$ rings, move the top $n$ rings to peg C ($2^n - 1$ moves by $P(n)$), move the bottom ring to B ($1$ move), then move the $n$ rings from C to B ($2^n - 1$ moves). This gives $2(2^n - 1) + 1 = 2^{n+1} - 1$ moves.

  Conversely, to move the bottom ring we must first clear the $n$ rings above it (at least $2^n - 1$ moves by $P(n)$), then move the bottom ring ($1$ move), then reassemble the $n$ rings (at least $2^n - 1$ moves). So at least $2^{n+1} - 1$ moves are needed.

  Hence $P(n) \Rightarrow P(n+1)$, and by the WPI, $P(n)$ holds for all $n$.
\end{eg}

\begin{eg}[A false proof]
  \emph{Claim:} all numbers are equal. Let $P(n)$ be the statement ``in any set of $n$ numbers, all elements are equal''. $P(1)$ is trivially true. Suppose $P(n)$ holds. Given $\{a_1, a_2, \ldots, a_{n+1}\}$, apply $P(n)$ to $\{a_1, \ldots, a_n\}$ and to $\{a_2, \ldots, a_{n+1}\}$ to conclude $a_1 = \cdots = a_n$ and $a_2 = \cdots = a_{n+1}$. Hence $a_1 = a_2 = \cdots = a_{n+1}$.
\end{eg}

\begin{remark}
  The error is in the step $P(1) \Rightarrow P(2)$. When $n = 1$, the sets $\{a_1\}$ and $\{a_2\}$ do not overlap, so we cannot conclude $a_1 = a_2$. The inductive step is valid only for $n \geq 2$.
\end{remark}

We can now give a proof of the inclusion-exclusion principle by induction.
\begin{thm}[Inclusion-exclusion principle, by induction]
  Let $A_1, \ldots, A_n$ be subsets of a finite set $X$. Then
  \[
    |A_1\cup \cdots \cup A_n| = \sum_i|A_i| - \sum_{i < j} |A_i\cap A_j| + \cdots + (-1)^{n-1} |A_1\cap A_2\cap \cdots \cap A_n|.
  \]
\end{thm}

\begin{proof}
  Let $P(n)$ be the statement that the inclusion-exclusion formula holds for any $n$ subsets of a finite set.

  $P(1)$ is trivially true, and $P(2)$ was proved above. Given $A_1, \ldots, A_{n+1}$, let $B_i = A_i\cap A_{n+1}$ for $1 \leq i\leq n$. Note that $B_i\cap B_j = A_i\cap A_j \cap A_{n+1}$, and similarly for higher-order intersections. By $P(2)$:
  \[
    |A_1\cup \cdots \cup A_{n+1}| = |A_1\cup \cdots \cup A_n| + |A_{n+1}| - |B_1\cup \cdots \cup B_n|.
  \]
  Applying $P(n)$ to both $A_1, \ldots, A_n$ and $B_1, \ldots, B_n$:
  \begin{align*}
    |A_1\cup \cdots \cup A_{n + 1}| &= \sum_{i\leq n}|A_i| - \sum_{i < j\leq n}|A_i\cap A_j| + \cdots + |A_{n + 1}| \\
    &\quad -\sum_{i \leq n}|B_i| + \sum_{i < j\leq n}|B_i\cap B_j| - \cdots
  \end{align*}
  Since $\sum_{i\leq n}|B_i| = \sum_{i\leq n}|A_i\cap A_{n+1}|$, we can combine $\sum_{i < j\leq n}|A_i\cap A_j|$ and $\sum_{i\leq n}|B_i|$ to obtain $\sum_{i< j \leq n+1}|A_i \cap A_j|$, and similarly for the higher-order terms. This gives the inclusion-exclusion formula for $n+1$ sets.

  Hence $P(n)\Rightarrow P(n + 1)$ for $n\geq 2$, and by the WPI, $P(n)$ holds for all $n$.
\end{proof}

\begin{remark}
  The WPI is not sufficient for arguments like ``every number is a product of primes'', where the inductive step decomposes $n$ into factors that may be much smaller than $n - 1$. We need a stronger form of induction.
\end{remark}

\begin{thm}[Strong Principle of Induction]
  Let $P(n)$ be a statement about $n\in \N$. Suppose that
  \begin{enumerate}
    \item $P(1)$ is true, and
    \item $(\forall n \in \N)\;[P(k) \text{ true } \forall k < n] \Rightarrow P(n)$.
  \end{enumerate}
  Then $P(n)$ is true for all $n\in \N$.
\end{thm}

\begin{remark}
  Condition (i) is redundant, since it follows from (ii) by taking $n = 1$ (the hypothesis ``$P(k)$ true for all $k < 1$'' is vacuously true). We state it for clarity.
\end{remark}

\begin{eg}[Evolutionary trees]
  A mutant organism produces exactly two offspring, each of which is either an animal or another mutant. A possible tree:
  \tikzstyle{level 1}=[level distance=1cm, sibling distance=3.5cm]
  \tikzstyle{level 2}=[level distance=1cm, sibling distance=2cm]
  \begin{center}
    \begin{tikz}
      \node {mutant}
      child {
        node {mutant} edge from parent
        child {
          node {pig} edge from parent
        }
        child {
          node {mutant} edge from parent
          child {
            node {slug} edge from parent
          }
          child {
            node {man} edge from parent
          }
        }
      }
      child {
        node {mutant} edge from parent
        child {
          node {gnu} edge from parent
        }
        child {
          node {ibex} edge from parent
        }
      };
    \end{tikz}
  \end{center}
  \emph{Claim:} a tree with $n$ animals has exactly $n - 1$ mutants. Let $P(n)$ be this statement. $P(1)$ is clear. Given a tree with $n \geq 2$ animals, removing the root mutant yields two sub-trees with $n_1$ and $n_2$ animals, where $n_1 + n_2 = n$ and $n_1, n_2 < n$. By the strong inductive hypothesis, these sub-trees have $n_1 - 1$ and $n_2 - 1$ mutants respectively. So the total number of mutants is $1 + (n_1 - 1) + (n_2 - 1) = n - 1$. By the strong principle of induction, $P(n)$ holds for all $n$.
\end{eg}

\begin{prop}
  The strong principle of induction is equivalent to the weak principle of induction.
\end{prop}

\begin{proof}
  The strong principle clearly implies the weak, since $P(n) \Rightarrow P(n+1)$ implies $[P(k) \text{ true } \forall k \leq n] \Rightarrow P(n+1)$.

  Conversely, suppose the weak principle holds, and assume the hypotheses of the strong principle. Define $Q(n) = $ ``$P(k)$ is true for all $k\leq n$''. Then $Q(1)$ is true. If $Q(n)$ is true, then $P(1), \ldots, P(n)$ all hold, so by hypothesis (ii), $P(n+1)$ is true, giving $Q(n + 1)$. By the weak principle, $Q(n)$ holds for all $n$, and therefore so does $P(n)$.
\end{proof}

\begin{remark}
  Although equivalent, the two principles are conceptually distinct. Weak induction is based on the successor operation (``adding 1''), while strong induction exploits the ordering of the natural numbers.
\end{remark}

\begin{defi}[Partial order]
  A \emph{partial order} on a set $A$ is a relation $\leq$ on $A$ that is:
  \begin{enumerate}
    \item \emph{reflexive:} $a \leq a$ for all $a \in A$,
    \item \emph{antisymmetric:} if $a \leq b$ and $b \leq a$, then $a = b$,
    \item \emph{transitive:} if $a \leq b$ and $b \leq c$, then $a \leq c$.
  \end{enumerate}
\end{defi}

\begin{eg}
  The usual ordering $\leq$ on $\N$ is a partial order. The divisibility relation $a \mid b$ on $\N$ is also a partial order.
\end{eg}

\begin{defi}[Total order]
  A \emph{total order} is a partial order $\leq$ on $A$ such that for all $a, b \in A$, either $a \leq b$ or $b \leq a$.
\end{defi}

\begin{defi}[Well-ordering]
  A total order $\leq$ on $A$ is a \emph{well-ordering} if every non-empty subset of $A$ has a least element, i.e.\ for every non-empty $S \subseteq A$, there exists $m \in S$ such that $m \leq x$ for all $x \in S$.
\end{defi}

\begin{eg}
  $\Z$ with the usual order is not well-ordered: the set of even integers has no least element. The positive rationals $\Q^+$ are also not well-ordered under the usual order.
\end{eg}

\begin{thm}[Well-ordering principle]
  $\N$ is well-ordered under the usual ordering, i.e.\ every non-empty subset of $\N$ has a least element.
\end{thm}

\begin{prop}
  The well-ordering principle is equivalent to the strong principle of induction.
\end{prop}

\begin{proof}
  \emph{Well-ordering implies strong induction.} Suppose $P(k)$ true for all $k < n$ implies $P(n)$. If $P$ fails for some $n$, then the set $S = \{n\in \N : \neg P(n)\}$ is non-empty. By well-ordering, $S$ has a least element $m$. Since $m$ is the smallest counterexample, $P(k)$ holds for all $k < m$. But then $P(m)$ must hold by hypothesis, contradicting $m \in S$. Hence $P(n)$ is true for all $n$.

  \emph{Strong induction implies well-ordering.} Let $S\subseteq \N$ be non-empty and suppose $S$ has no least element. Let $P(n)$ be the statement ``$n \notin S$''. Then $P(1)$ is true (otherwise $1$ would be the least element of $S$). If $P(k)$ holds for all $k < n$, then no element less than $n$ belongs to $S$, so $n \notin S$ (otherwise $n$ would be the least element). Hence $P(n)$ holds. By strong induction, $P(n)$ is true for all $n$, i.e.\ $S = \emptyset$, a contradiction.
\end{proof}

\begin{remark}
  The well-ordering principle provides a useful proof technique: the \emph{method of minimal counterexample}. To prove $P(n)$ for all $n$, assume it fails and consider the smallest $n$ for which $P(n)$ is false. Then derive a contradiction.
\end{remark}

\begin{eg}
  \emph{Every $n \geq 2$ is a product of primes} (by minimal counterexample). Suppose not. By well-ordering, there exists a smallest $n$ that cannot be written as a product of primes. Then $n$ is not prime, so $n = ab$ with $1 < a, b < n$. By minimality of $n$, both $a$ and $b$ are products of primes. Hence so is $n$, a contradiction.
\end{eg}

\begin{eg}
  All natural numbers are interesting. Suppose not. Then there exists a smallest uninteresting number. But the property of being the smallest uninteresting number is itself interesting --- contradiction.
\end{eg}

\begin{eg}[Ackermann function]
  Consider the lexicographic order on $\N_0\times \N_0$: define $(a, b) \leq (c, d)$ if $a < c$, or $a = c$ and $b\leq d$. This is a total order. The Ackermann function $A:\N_0\times \N_0 \to \N$ is defined by
  \[
    A(m, n) =\begin{cases}n+1 & \text{if } m = 0, \\A(m-1, 1) & \text{if } m > 0 \text{ and } n = 0, \\A(m-1, A(m, n-1)) & \text{if } m > 0 \text{ and } n > 0.\end{cases}
  \]
  Each recursive call evaluates $A$ at a lexicographically smaller argument, so $A$ is well-defined provided the lexicographic order on $\N_0 \times \N_0$ is a well-ordering.

  To see this, let $S\subseteq \N_0\times \N_0$ be non-empty. Let $m$ be the least first coordinate appearing in $S$ (exists by well-ordering of $\N_0$), and let $n$ be the least second coordinate among pairs in $S$ with first coordinate $m$. Then $(m, n)$ is the least element of $S$.
\end{eg}

\section{Modular arithmetic}
\subsection{Modular arithmetic}
\begin{defi}[Congruence]
  Let $a, b\in \Z$ and $m \in \N$. We say $a$ and $b$ are \emph{congruent modulo} $m$, written
  \[
    a\equiv b\pmod m,
  \]
  if $m \mid (a - b)$. Equivalently, $a$ and $b$ have the same remainder upon division by $m$.
\end{defi}

\begin{eg}
  $9 \equiv 0\pmod 3$, \quad $11\equiv 6\pmod 5$.
\end{eg}

\begin{eg}
  The check digits of the ISBN are calculated modulo 11.
\end{eg}

\begin{prop}
  If $a\equiv b\pmod m$ and $d \mid m$, then $a \equiv b\pmod d$.
\end{prop}

\begin{proof}
  Since $m \mid (a - b)$ and $d \mid m$, we have $d \mid (a - b)$, i.e.\ $a \equiv b\pmod d$.
\end{proof}

\begin{remark}
  For fixed $m$, congruence modulo $m$ is an equivalence relation on $\Z$. The set of equivalence classes is denoted $\Z_m$ or $\Z/m\Z$.
\end{remark}

\begin{eg}
  $\Z_3 = \{[0], [1], [2]\}$.
\end{eg}

\begin{prop}
  If $a\equiv b\pmod m$ and $u\equiv v \pmod m$, then
  \[
    a + u\equiv b + v\pmod m \quad \text{and} \quad au \equiv bv \pmod m.
  \]
\end{prop}

\begin{proof}
  For addition: $m \mid (a - b) + (u - v) = (a + u) - (b + v)$, so $a + u\equiv b + v\pmod m$.

  For multiplication: $m \mid (a - b)u + b(u - v) = au - bv$, so $au \equiv bv \pmod m$.
\end{proof}

\begin{remark}
  This shows that addition and multiplication are well-defined on the congruence classes $\Z_m$. For example, in $\Z_7$, $[4] + [5] = [9] = [2]$.
\end{remark}

\begin{eg}
  The equation $2a^2 + 3b^3 = 1$ has no solutions in $\Z$. Working modulo $3$: if a solution existed, then $2a^2 \equiv 1\pmod 3$. But checking all residues, $2\cdot 0^2 \equiv 0$, $2\cdot 1^2\equiv 2$ and $2\cdot 2^2 \equiv 2 \pmod 3$. So the congruence has no solution, and hence neither does the original equation.
\end{eg}

\begin{remark}
  Every odd number is congruent to either $1$ or $-1$ modulo $4$. In particular, every odd prime $p$ satisfies $p \equiv 1$ or $p \equiv -1 \pmod 4$.
\end{remark}

\begin{thm}
  There are infinitely many primes $p \equiv -1 \pmod 4$.
\end{thm}

\begin{proof}
  Suppose not, and let $p_1, \ldots, p_k$ be all primes congruent to $-1$ modulo $4$. Let $N = 4p_1 p_2 \cdots p_k - 1$. Then $N\equiv -1\pmod 4$. Write $N = q_1 q_2 \cdots q_\ell$ as a product of primes. Since $N$ is odd, $2 \nmid N$, and $p_i\nmid N$ for all $i$. So every $q_j \equiv 1\pmod 4$, which gives $N = q_1 q_2 \cdots q_\ell \equiv 1\pmod 4$, a contradiction.
\end{proof}

\begin{eg}
  Solve $7x \equiv 2 \pmod {10}$. Since $3\cdot 7 = 21 \equiv 1\pmod {10}$, multiplying both sides by $3$ gives $x \equiv 3\cdot 2 = 6\pmod {10}$.
\end{eg}

\begin{defi}[Unit]
  Let $m \in \N$. An integer $u$ is a \emph{unit modulo $m$} if there exists $v \in \Z$ such that $uv \equiv 1\pmod m$. We call $v$ the \emph{inverse} of $u$ modulo $m$.
\end{defi}

\begin{remark}
  Not every integer has an inverse modulo $m$. For instance, $2$ is not a unit modulo $10$.
\end{remark}

\begin{prop}
  $u$ is a unit modulo $m$ if and only if $(u, m) = 1$.
\end{prop}

\begin{proof}
  ($\Rightarrow$) If $uv \equiv 1\pmod m$, then $uv - mn = 1$ for some $n \in \Z$. Hence $1$ is a linear combination of $u$ and $m$, so $(u, m) = 1$.

  ($\Leftarrow$) If $(u, m) = 1$, then by B\'{e}zout's identity there exist $a, b \in \Z$ with $ua + mb = 1$. Hence $ua \equiv 1\pmod m$, so $u$ is a unit with inverse $a$.
\end{proof}

\begin{remark}
  The inverse of a unit can be computed efficiently using Euclid's algorithm.
\end{remark}

\begin{cor}
  If $(a, m) = 1$, then the congruence $ax \equiv b\pmod m$ has a unique solution modulo $m$.
\end{cor}

\begin{proof}
  Since $(a, m) = 1$, the inverse $a^{-1}$ exists modulo $m$. Multiplying $ax\equiv b$ by $a^{-1}$ gives $x\equiv a^{-1}b\pmod m$. Conversely, if $x \equiv a^{-1}b$, then $ax \equiv aa^{-1}b \equiv b \pmod m$.
\end{proof}

\begin{prop}
  The congruence $ax \equiv b\pmod m$ has a solution if and only if $(a, m) \mid b$. If $d = (a, m)$ divides $b$, then the solutions are precisely the solutions to $\frac{a}{d}x \equiv \frac{b}{d} \pmod {\frac{m}{d}}$.
\end{prop}

\begin{proof}
  Let $d = (a, m)$. If $ax \equiv b\pmod m$ has a solution, then $m \mid (ax - b)$, so $d \mid (ax - b)$. Since $d \mid a$, we have $d \mid b$.

  Conversely, suppose $d \mid b$. Write $a = da'$, $b = db'$ and $m = dm'$. Then
  \[
    ax \equiv b\pmod m \;\Leftrightarrow\; da'x \equiv db'\pmod{dm'} \;\Leftrightarrow\; a'x \equiv b'\pmod{m'}.
  \]
  Since $(a', m') = 1$, this has a unique solution modulo $m'$.
\end{proof}

\begin{eg}
  $2x \equiv 3 \pmod 4$ has no solution since $(2, 4) = 2$ does not divide $3$.
\end{eg}

\subsection{Multiple moduli}
\begin{eg}
  Suppose $x \equiv 2\pmod 3$ and $x\equiv 1\pmod 4$. Working modulo $12$: the first congruence gives $x \equiv 2, 5, 8$ or $11 \pmod {12}$, while the second gives $x \equiv 1, 5$ or $9\pmod {12}$. Combining, $x \equiv 5\pmod {12}$. Conversely, $x\equiv 5\pmod {12}$ implies both original congruences.
\end{eg}

\begin{thm}[Chinese remainder theorem]
  Let $m, n \in \N$ with $(m, n) = 1$, and let $a, b\in \Z$. Then the simultaneous congruences
  \[
    x\equiv a\pmod m, \qquad x\equiv b\pmod n
  \]
  have a unique solution modulo $mn$.
\end{thm}

\begin{proof}
  Since $(m, n) = 1$, by B\'{e}zout's identity there exist $u, v\in \Z$ with $um + vn = 1$. Then $vn \equiv 1\pmod m$ and $um \equiv 1 \pmod n$. Set $x = umb + vna$. Then $x\equiv vna \equiv a\pmod m$ and $x\equiv umb \equiv b\pmod n$.

  For uniqueness, suppose $y$ is another solution. Then $y \equiv x\pmod m$ and $y\equiv x\pmod n$, so $m \mid (y - x)$ and $n \mid (y - x)$. Since $(m, n) = 1$, we have $mn \mid (y - x)$, i.e.\ $y \equiv x\pmod {mn}$.
\end{proof}

\begin{remark}
  A congruence modulo $mn$ (with $(m,n)=1$) is equivalent to a pair of congruences modulo $m$ and modulo $n$. This extends to any number of pairwise coprime moduli by repeated application.
\end{remark}

\begin{prop}
  Let $(m, n) = 1$. Then $c$ is a unit modulo $mn$ if and only if $c$ is a unit both modulo $m$ and modulo $n$.
\end{prop}

\begin{proof}
  ($\Rightarrow$) If $cu \equiv 1 \pmod {mn}$, then $cu \equiv 1\pmod m$ and $cu\equiv 1\pmod n$.

  ($\Leftarrow$) Suppose $cu\equiv 1\pmod m$ and $cv \equiv 1\pmod n$. By the Chinese remainder theorem, there exists $w$ with $w\equiv u \pmod m$ and $w\equiv v\pmod n$. Then $cw\equiv 1\pmod m$ and $cw\equiv 1\pmod n$. Since the integer $1$ also satisfies both congruences, uniqueness gives $cw\equiv 1\pmod {mn}$.
\end{proof}

\begin{defi}[Euler's totient function]
  For $m \in \N$, \emph{Euler's totient function} $\phi(m)$ is the number of integers $a$ with $1\leq a\leq m$ and $(a, m) = 1$. Equivalently, $\phi(m)$ is the number of units modulo $m$.
\end{defi}

\begin{prop}\leavevmode
  \begin{enumerate}
    \item If $(m, n) = 1$, then $\phi(mn) = \phi(m)\phi(n)$ (i.e.\ $\phi$ is \emph{multiplicative}).
    \item If $p$ is prime, then $\phi(p) = p - 1$.
    \item If $p$ is prime and $k \geq 1$, then $\phi(p^k) = p^k - p^{k - 1} = p^k(1 - 1/p)$.
    \item $\displaystyle\phi(m) = m\prod_{p \mid m}(1 - 1/p)$, where the product is over all prime divisors of $m$.
  \end{enumerate}
\end{prop}

\begin{proof}
  Parts (i)--(iii) follow from the definitions. We give two proofs of (iv).

  \emph{First proof.} Write $m = p_1^{k_1} p_2^{k_2} \cdots p_\ell^{k_\ell}$. By (i) and (iii):
  \[
    \phi(m) = \phi(p_1^{k_1})\cdots \phi(p_\ell^{k_\ell}) = p_1^{k_1}(1-1/p_1)\cdots p_\ell^{k_\ell}(1 - 1/p_\ell) = m\prod_{p \mid m}(1 - 1/p).
  \]

  \emph{Second proof.} Let $X = \{0, 1, \ldots, m - 1\}$ and $A_j = \{x\in X: p_j\mid x\}$. Then $|A_j| = m/p_j$, $|A_i\cap A_j| = m/(p_ip_j)$, etc. By inclusion-exclusion:
  \[
    \phi(m) = |\bar A_1\cap \bar A_2\cap \cdots \cap \bar A_\ell| = m\prod_{p \mid m}(1 - 1/p). \qedhere
  \]
\end{proof}

\begin{eg}
  $\phi(60) = 60(1 - 1/2)(1 - 1/3)(1 - 1/5) = 16$.
\end{eg}

\begin{remark}
  If $a$ and $b$ are both units modulo $m$, then so is $ab$ (since $au \equiv 1$ and $bv \equiv 1$ imply $(ab)(uv)\equiv 1$). Hence the units modulo $m$ form a multiplicative group of order $\phi(m)$.
\end{remark}

\subsection{Prime moduli}
\begin{thm}[Wilson's theorem]
  Let $p$ be a prime. Then $(p - 1)! \equiv -1\pmod p$.
\end{thm}

\begin{proof}
  Since $p$ is prime, the elements $1, 2, \ldots, p - 1$ are all units modulo $p$. We first determine which elements are their own inverses: $x^2 \equiv 1 \pmod p$ if and only if $p \mid (x-1)(x+1)$, i.e.\ $x \equiv \pm 1 \pmod p$.

  So among $1, 2, \ldots, p-1$, only $1$ and $p - 1 \equiv -1$ are self-inverse. The remaining $p - 3$ elements pair off into $(p - 3)/2$ inverse pairs, each contributing $1$ to the product. Hence $(p - 1)! \equiv 1 \cdot (-1) = -1 \pmod p$.
\end{proof}

\begin{thm}[Fermat's little theorem]
  Let $p$ be a prime. Then $a^p \equiv a\pmod p$ for all $a\in \Z$. Equivalently, $a^{p - 1}\equiv 1\pmod p$ for all $a\not\equiv 0 \pmod p$.
\end{thm}

\begin{proof}
  We give two proofs of the second form.

  \emph{First proof.} The elements $\{1, 2, \ldots, p - 1\}$ form a multiplicative group of order $p - 1$ modulo $p$. So $a^{p - 1} \equiv 1$ by Lagrange's theorem.

  \emph{Second proof.} If $a\not\equiv 0\pmod p$, then $a$ is a unit, so $ax \equiv ay \pmod p$ implies $x\equiv y\pmod p$. Hence $a, 2a, 3a, \ldots, (p - 1)a$ are distinct modulo $p$, and therefore form a permutation of $1, 2, \ldots, p -1$. Multiplying:
  \[
    a \cdot 2a \cdot 3a \cdots (p - 1)a \equiv 1 \cdot 2 \cdot 3 \cdots (p - 1) \pmod p.
  \]
  Hence $a^{p - 1}(p - 1)! \equiv (p - 1)! \pmod p$, and since $(p-1)!$ is a unit, $a^{p - 1} \equiv 1$.
\end{proof}

\begin{remark}
  Neither Wilson's nor Fermat's theorem holds when the modulus is not prime. However, Fermat's theorem admits the following generalisation.
\end{remark}

\begin{thm}[Fermat--Euler theorem]
  Let $a, m \in \N$ with $(a, m) = 1$. Then $a^{\phi(m)} \equiv 1\pmod m$.
\end{thm}

\begin{proof}
  Let $U = \{u_1, u_2, \ldots, u_{\phi(m)}\}$ be the set of units modulo $m$. Since $a$ is a unit, multiplication by $a$ permutes $U$: the elements $au_1, au_2, \ldots, au_{\phi(m)}$ are distinct units, hence equal to $u_1, \ldots, u_{\phi(m)}$ in some order. Multiplying:
  \[
    a^{\phi(m)} \cdot u_1 u_2 \cdots u_{\phi(m)} \equiv u_1 u_2 \cdots u_{\phi(m)} \pmod m.
  \]
  Since the product $z = u_1 u_2 \cdots u_{\phi(m)}$ is a unit, we may cancel to obtain $a^{\phi(m)} \equiv 1$.
\end{proof}

\begin{defi}[Quadratic residue]
  Let $p$ be an odd prime. An integer $a \not\equiv 0 \pmod p$ is a \emph{quadratic residue} modulo $p$ if $a \equiv x^2 \pmod p$ for some $x$. Otherwise, $a$ is a \emph{quadratic non-residue}.
\end{defi}

\begin{remark}
  If $a^2 \equiv b^2\pmod p$, then $p \mid (a - b)(a + b)$, so $a\equiv \pm b\pmod p$. Thus each quadratic residue is the square of exactly two elements of $\{1, 2, \ldots, p-1\}$, and there are exactly $(p-1)/2$ quadratic residues modulo $p$.
\end{remark}

\begin{eg}
  For $p = 7$: $1^2 \equiv 6^2 \equiv 1$, $2^2 \equiv 5^2 \equiv 4$, $3^2 \equiv 4^2 \equiv 2$. So $1, 2, 4$ are quadratic residues and $3, 5, 6$ are not.
\end{eg}

\begin{prop}
  Let $p$ be an odd prime. Then $-1$ is a quadratic residue modulo $p$ if and only if $p\equiv 1\pmod 4$.
\end{prop}

\begin{proof}
  Suppose $p \equiv 1 \pmod 4$, say $p = 4k + 1$. By Wilson's theorem:
  \begin{align*}
    -1 &\equiv (p - 1)! = 1 \cdot 2 \cdots (2k) \cdot (2k+1) \cdots (4k) \pmod p.
  \end{align*}
  Now $4k \equiv -1$, $4k - 1 \equiv -2$, \ldots, $2k + 1 \equiv -2k$, so
  \[
    -1 \equiv (2k)! \cdot (-1)^{2k} (2k)! = ((2k)!)^2 \pmod p.
  \]
  Hence $-1$ is a quadratic residue.

  Conversely, suppose $p = 4k + 3$ and $-1 \equiv z^2 \pmod p$ for some $z$. By Fermat's little theorem:
  \[
    1 \equiv z^{p - 1} = (z^2)^{2k + 1} \equiv (-1)^{2k + 1} = -1 \pmod p,
  \]
  giving $p \mid 2$, which is impossible for an odd prime.
\end{proof}

\begin{prop}[stated without proof]
  A prime $p$ is the sum of two squares if and only if $p = 2$ or $p\equiv 1\pmod 4$.
\end{prop}

\begin{prop}
  There are infinitely many primes $p \equiv 1\pmod 4$.
\end{prop}

\begin{proof}
  Suppose not, and let $p_1, \ldots, p_k$ be all such primes. Let $N = (2p_1 \cdots p_k)^2 + 1$. Then $N$ is odd and not divisible by any $p_i$. Let $q$ be a prime factor of $N$. Then $q \not\equiv 1 \pmod 4$, so $q \equiv -1 \pmod 4$ (since $q$ is odd). But $(2p_1 \cdots p_k)^2 \equiv -1\pmod q$, so $-1$ is a quadratic residue modulo $q$, contradicting $q \equiv -1 \pmod 4$.
\end{proof}

\begin{prop}
  Let $p = 4k + 3$ be a prime and let $a$ be a quadratic residue modulo $p$. Then $a \equiv (\pm a^{k + 1})^2 \pmod p$.
\end{prop}

\begin{proof}
  Write $a \equiv z^2 \pmod p$. By Fermat's little theorem, $a^{2k + 1} \equiv z^{4k + 2} = z^{p - 1} \equiv 1$. Multiplying by $a$ gives $a^{2(k+1)} \equiv a \pmod p$, i.e.\ $(\pm a^{k + 1})^2 \equiv a \pmod p$.
\end{proof}

\begin{remark}[Efficient computation]
  The preceding proposition allows us to compute square roots modulo $p \equiv 3 \pmod 4$ efficiently, provided we can compute large powers efficiently. This is achieved by \emph{repeated squaring}: to compute $a^n$, write $n$ in binary and square-and-multiply. For example, $a^{37} = a^{32} \cdot a^{4} \cdot a$. This gives time complexity $O(\log n)$.
\end{remark}

\begin{remark}
  If $n = pq$ is a product of two distinct primes, and $a$ is a quadratic residue modulo $n$, then $a$ is a square modulo both $p$ and $q$. There are two square roots modulo $p$ (say $\pm s$) and two modulo $q$ (say $\pm t$). By the Chinese remainder theorem, these give $4$ distinct square roots of $a$ modulo $n$.
\end{remark}

\subsection{Public-key (asymmetric) cryptography}
\subsubsection*{Tossing a coin over a phone}
Alice and Bob wish to toss a fair coin over the phone. Alice chooses two large primes $p, q\equiv 3\pmod 4$ and tells Bob the product $n = pq$. Bob picks a number $u$ coprime to $n$, computes $a\equiv u^2\pmod n$, and tells Alice the value of $a$.

Alice computes the four square roots of $a$ modulo $n$ (in time $O(\log n)$), obtaining $\pm u$ and $\pm v$, and tells Bob one of these pairs. If Alice picks $\pm u$, Bob says ``you win''; otherwise, Bob says ``you lose''.

Can Bob cheat? To claim Alice lost when she announced $\pm u$, Bob must produce the other pair $\pm v$. But knowing both $\pm u$ and $\pm v$ allows factorisation of $n$: since $u^2 \equiv v^2\pmod n$, we have $n \mid (u - v)(u + v)$ with $n\nmid (u - v)$ and $n\nmid (u + v)$, so $p = (n, u - v)$ and $q = (n, u + v)$. Thus cheating is as hard as factorisation.

\begin{remark}[Generating large primes]
  The protocol requires large primes. To find them, we repeatedly choose random numbers and test for primality. Primality can be tested efficiently using Fermat-like checks: for random bases $a$, compute $a^{p-1} \pmod p$. If the result is not $1$, then $p$ is definitely composite. Sufficiently many tests passing gives high (though not absolute) confidence that $p$ is prime.
\end{remark}

\subsubsection*{RSA encryption}
In \emph{asymmetric} (or \emph{public-key}) encryption, anyone can encrypt a message, but only the intended recipient can decrypt it. The RSA cryptosystem (Rivest, Shamir, Adleman) achieves this as follows.

\emph{Key generation.} Bob chooses two large primes $p, q$ and computes $n = pq$. He picks $e$ coprime to $\phi(n) = (p - 1)(q - 1)$ and computes $d$ with $de \equiv 1\pmod {\phi(n)}$. Bob publishes the \emph{public key} $(n, e)$ and keeps the \emph{private key} $d$ secret.

\emph{Encryption.} To send a message $M < n$ to Bob, Alice computes $C \equiv M^e \pmod n$ and sends $C$.

\emph{Decryption.} Bob computes $C^d \equiv M^{ed} = M^{k\phi(n) + 1} \equiv M\pmod n$ by the Fermat--Euler theorem.

\begin{remark}[Security]
  An eavesdropper Eve can recover $M$ by factorising $n$ (which gives $\phi(n)$ and hence $d$). However, factorisation of large integers is believed to be computationally hard. Whether RSA can be broken \emph{without} factorising $n$ remains an open question.
\end{remark}

\section{Real numbers}
\begin{remark}[The axiomatic approach]
  We define each number system (e.g.\ the real numbers) as a set equipped with operations satisfying certain \emph{axioms}. Two questions arise: does such a set exist, and is it unique?

  Existence is established by an explicit construction. However, the construction serves only to show that the axioms are consistent; we do not regard the constructed objects as what the numbers ``really are.'' For example, we will construct a real number as a pair of subsets of $\Q$, but it would be absurd to ask whether
  \[
    \exists x\colon x \in 3 \vee x \in \pi.
  \]
  Uniqueness is more subtle: different constructions yield isomorphic structures, but the proofs are non-trivial (cf.\ IID Logic and Set Theory).

  In practice, we work only with the axioms, not with any particular construction. For the natural numbers and the real numbers we give both axioms and constructions; for the integers and rationals we give constructions only.
\end{remark}

\subsection{Construction of numbers}
\subsubsection*{Construction of natural numbers}
\begin{defi}[Natural numbers]
  The set of natural numbers $\N$ is defined by \emph{Peano's axioms}. We call $\N$ the ``natural numbers'' if it has a distinguished element $0$ and a map $S\colon \N \to \N$ (the \emph{successor} map, intuitively $n \mapsto n + 1$) such that:
  \begin{enumerate}
    \item $S(n) \neq 0$ for all $n \in \N$.
    \item For all $n, m \in \N$, if $S(n) = S(m)$, then $n = m$.
    \item (\emph{Axiom of induction}.) For any subset $A \subseteq \N$, if $0 \in A$ and $n \in A \Rightarrow S(n) \in A$, then $A = \N$.
  \end{enumerate}

  We write $1 = S(0)$, $2 = S(1)$, $3 = S(2)$, etc. One can prove that the axiom of induction allows functions on $\N$ to be defined recursively (cf.\ IID Logic and Set Theory). Assuming this, we define addition and multiplication recursively by
  \begin{align*}
    n + 0 &= n &n\times 0 &= 0\\
    n + S(m) &= S(n + m) & n \times S(m) &= n \times m + n
  \end{align*}
  and verify by induction that these satisfy the usual rules (associativity, commutativity, distributivity).
\end{defi}

\begin{remark}[Explicit construction]
  We can set $0 = \emptyset$, $1 = \{0\}$, $2 = \{0, 1\}$, and in general $S(n) = n \cup \{n\}$. This is in some sense circular: defining the natural numbers recursively presupposes recursion, which itself relies on the natural numbers. Making this rigorous requires a different approach; details are left to the IID Logic and Set Theory course.
\end{remark}

\subsubsection*{Construction of integers}
\begin{defi}[Integers]
  $\Z$ is obtained from $\N$ by allowing subtraction. Formally, we define $\Z$ to be the equivalence classes of $\N\times \N$ under the equivalence relation
  \[
    (a, b) \sim (c, d) \quad\text{if and only if}\quad a + d = b + c.
  \]
  Intuitively, we think of $(a, b)$ as $a - b$.

  We write $a$ for $[(a, 0)]$ and $-a$ for $[(0, a)]$, and define the operations by
  \begin{align*}
    (a, b) + (c, d) &= (a + c, b + d)\\
    (a, b)\times (c, d) &= (ac + bd, ad + bc).
  \end{align*}
  We can check that these are well-defined and satisfy the usual properties.
\end{defi}

\subsubsection*{Construction of rationals}
\begin{defi}[Rationals]
  $\Q$ is obtained from $\Z$ by allowing division. Formally, we define $\Q$ to be the equivalence classes of $\Z \times (\N \setminus \{0\})$ under the relation
  \[
    (a, b) \sim (c, d)\quad\text{if and only if}\quad ad = bc.
  \]
  We write $\frac{a}{b}$ for $[(a, b)]$. We define
  \begin{align*}
   (a, b) + (c, d) &= (ad + bc, bd)\\
   (a, b)\times (c, d) &= (ac, bd).
  \end{align*}
  We can check that these are well-defined and satisfy the usual properties.
\end{defi}

\begin{defi}[Totally ordered field]
  A set $F$ equipped with binary operations $+, \times$ and relation $\leq$ is a \emph{totally ordered field} if
  \begin{enumerate}
    \item $F$ is an additive abelian group with identity $0$.
    \item $F\setminus \{0\}$ is a multiplicative abelian group with identity $1$.
    \item Multiplication is distributed over addition: $a(b + c) = ab + ac$.
    \item $\leq$ is a total order.
    \item For any $p, q, r \in F$, if $p \leq q$, then $p + r \leq q+ r$.
    \item For any $p, q, r \in F$, if $p \leq q$ and $0 \leq r$, then $p r \leq qr$.
  \end{enumerate}
\end{defi}

\begin{prop}
  $\Q$ is a totally ordered field.
\end{prop}

\begin{eg}
  For $p$ prime, $\Z_p$ is a field but cannot be made into a totally ordered field: in any ordered field $1 > 0$ implies $1 + 1 > 0$, $1 + 1 + 1 > 0$, etc., so the field must have characteristic $0$.
\end{eg}
\begin{prop}
  $\Q$ is densely ordered, i.e.\ for any $p, q \in \Q$, if $p < q$, then there is some $r \in \Q$ such that $p < r < q$.
\end{prop}
\begin{proof}
  Take $r = \frac{p + q}{2}$.
\end{proof}

However, $\Q$ is not enough for our purposes.
\begin{prop}
  There is no rational $q\in \Q$ with $q^2 = 2$.
\end{prop}

\begin{proof}
  Suppose not, and $(\frac{a}{b})^2 = 2$, where $b$ is chosen as small as possible. We will derive a contradiction in four ways.
  \begin{enumerate}
    \item $a^2 = 2b^2$. So $a$ is even. Let $a = 2a'$. Then $b^2 = 2a'^2$. Then $b$ is even as well, and $b = 2b'$. But then $\frac{a}{b} = \frac{a'}{b'}$ with a smaller $b'$. Contradiction.
    \item We know that $b$ is a product of primes if $b \not= 1$. Let $p \mid b$. Then $a^2 = 2b^2$. So $p \mid a^2$. So $p \mid a$. Contradict $b$ minimal.
    \item (Dirichlet) We have $\frac{a}{b} = \frac{2b}{a}$. So $a^2 = 2b^2$. For any, $u, v$, we have $a^2v = 2b^2v$ and thus $uab + a^2v = uab + 2b^2v$. So $\frac{a}{b} = \frac{au + 2bv}{bu + av}$. Put $u = -1, v = 1$. Then $\frac{a}{b} = \frac{2b - a}{a - b}$. Since $a < 2b, a - b < b$. So we have found a rational with smaller $b$.
    \item Same as 3, but pick $u, v$ so $bu + av = 1$ since $a$ and $b$ are coprime. So $\frac{a}{b}$ is an integer.\qedhere
  \end{enumerate}
\end{proof}

\subsubsection*{Construction of real numbers}
\begin{remark}
  The rational numbers are incomplete: the set $\{q \in \Q : q^2 < 2\}$ is bounded above in $\Q$ but has no rational supremum. The correct way to express this deficiency is not in terms of polynomial equations (e.g.\ $x^2 + 1 = 0$ has no real solution either, and transcendental numbers like $\pi$ are not algebraic), but in terms of \emph{least upper bounds}.
\end{remark}

\begin{defi}[Least upper bound/supremum and greatest lower bound/infimum]
  Let $X$ be an ordered set. An element $s \in X$ is a \emph{least upper bound} (or \emph{supremum}) for $S \subseteq X$, written $s = \sup S$, if
  \begin{enumerate}
    \item $s$ is an upper bound for $S$, i.e.\ $x \leq s$ for every $x \in S$;
    \item if $t$ is any upper bound for $S$, then $s \leq t$.
  \end{enumerate}
  Similarly, $s \in X$ is a \emph{greatest lower bound} (or \emph{infimum}), written $s = \inf S$, if $s$ is a lower bound for $S$ and every lower bound $t$ satisfies $t \leq s$.
\end{defi}

\begin{remark}
  By definition, the least upper bound of $S$, if it exists, is unique.
\end{remark}

\begin{defi}[Real numbers]
  The \emph{real numbers} $\R$ is a totally ordered field containing $\Q$ that satisfies the following axiom.
\end{defi}

\begin{axiom}[Least upper bound axiom]
  Every non-empty subset of $\R$ that has an upper bound has a least upper bound.
\end{axiom}

\begin{remark}
  The requirement ``non-empty'' is necessary: every real number is an upper bound of $\emptyset$, so $\emptyset$ has no \emph{least} upper bound. The explicit construction of $\R$ from $\Q$ is deferred to the end of this section.
\end{remark}

\begin{remark}[Embedding of $\Q$ in $\R$]
  Since $\R$ is a field, it has a multiplicative identity $1$. We define the natural numbers by $n = \underbrace{1 + \cdots + 1}_{n\text{ times}}$, the negative integers via additive inverses, and the rationals via multiplicative inverses: $\frac{m}{n} = m \cdot n^{-1}$ for $n \neq 0$. This gives a canonical copy of $\Q$ inside $\R$.
\end{remark}

\begin{cor}
  Every non-empty subset of $\R$ bounded below has an infimum.
\end{cor}

\begin{proof}
  Let $S$ be non-empty and bounded below. Then $-S = \{-x : x \in S\}$ is non-empty and bounded above, so $\sup(-S)$ exists. One checks that $\inf S = -\sup(-S)$.
\end{proof}

\begin{proof}[Alternative proof]
  Let $L$ be the set of all lower bounds of $S$. Then $L$ is non-empty (since $S$ is bounded below) and bounded above (by any element of $S$), so $\sup L$ exists. For each $x \in S$, $x$ is an upper bound of $L$, so $\sup L \leq x$; hence $\sup L$ is a lower bound of $S$. Since every lower bound of $S$ lies in $L$, we have $t \leq \sup L$ for every lower bound $t$. Thus $\inf S = \sup L$.
\end{proof}

\begin{remark}
  The set $\{q \in \Q : q^2 < 2\}$ now has a supremum in $\R$, by the least upper bound axiom.
\end{remark}

\begin{defi}[Closed and open intervals]
  Let $a, b \in \R$ with $a \leq b$. The \emph{closed interval} $[a, b]$ is the set $\{x \in \R : a \leq x \leq b\}$.

  The \emph{open interval} $(a, b)$ is the set $\{x \in \R : a < x < b\}$.

  Similarly, we can have $[a, b) = \{x\in \R: a\leq x < b\}$ and $(a, b] = \{x\in \R: a< x \leq b\}$.
\end{defi}

\begin{eg}
  Let $S = [0, 1]$. Then $S\not= \emptyset$. Also $S$ has an upper bound, e.g.\ $2$. Hence $\sup S$ exists.

  To find it explicitly, notice that $1$ is an upper bound for $S$ by definition, and if $t < 1$, then $t$ is not an upper bound for $S$ since $1\in S$ but $1\not\leq t$. So every upper bound is at least $1$ and therefore $1$ is the supremum of $S$.

  Now let $T = (0, 1)$. Again $T$ is non-empty and has an upper bound (e.g.\ $2$). So again $\sup T$ exists. We know that $1$ is an upper bound. If $t < 0$, then $0.5 \in T$ but $0.5 \not\leq t$, so $t$ is not an upper bound. Now suppose $0 \leq t < 1$; then $0 < t < \frac{1 + t}{2} < 1$, so $\frac{1 + t}{2} \in T$ but $\frac{1 + t}{2} \not\leq t$. So $t$ is not an upper bound. So $\sup T = 1$.

  Note that these cases differ by $\sup S\in S$ but $\sup T\not\in T$. $S$ has a maximum element $1$ and the maximum is the supremum. $T$ doesn't have a maximum, but the supremum can still exist.
\end{eg}

\begin{thm}[Archimedean property]
  For every $r \in \R$, there exists $n \in \N$ with $n > r$.
\end{thm}

\begin{proof}
  Assume the contrary. Then $r$ is an upper bound for $\N$. $\N$ is not empty since $1\in \N$. By the least upper bound axiom, $s = \sup \N$ exists. Since $s$ is the least upper bound for $\N$, $s - 1$ is not an upper bound for $\N$. So $\exists m\in \N$ with $m > s - 1$. Then $m + 1\in \N$ but $m + 1 > s$, which contradicts the statement that $s$ is an upper bound.
\end{proof}

\begin{prop}
  $\inf\{\frac{1}{n} : n \in \N,\, n \geq 1\} = 0$.
\end{prop}

\begin{proof}
  Let $S = \{\frac{1}{n} : n \in \N,\, n \geq 1\}$. Certainly $0$ is a lower bound for $S$. If $t > 0$, by the Archimedean property there exists $n \in \N$ with $n > 1/t$, so $\frac{1}{n} < t$. Hence $\frac{1}{n} \in S$ but $\frac{1}{n} \not\geq t$, so $t$ is not a lower bound for $S$.
\end{proof}

\begin{thm}[Density of $\Q$ in $\R$]
  For all $r, s \in \R$ with $r < s$, there exists $q \in \Q$ with $r < q < s$.
\end{thm}

\begin{proof}
  Without loss of generality assume $r \geq 0$ (if $r < 0 < s$ take $q = 0$; if $s \leq 0$ apply the argument to $-s < -r$ and negate). Since $s - r > 0$, the Archimedean property gives $n \in \N$ with $\frac{1}{n} < s - r$. Again by the Archimedean property, there exists $N \in \N$ with $N > sn$.

  Let $T = \{k\in \N: \frac{k}{n}\geq s\}$. $T$ is not empty, since $N\in T$. Then by the well-ordering principle, $T$ has a minimum element $m$. Now $m\not= 1$ since $\frac{1}{n} < s - r \leq s$. Let $q = \frac{m - 1}{n}$. Since $m - 1\not\in T$, $q < s$. If $q =\frac{m - 1}{n}< r$, then $\frac{m}{n} < r + \frac{1}{n} < s$, so $m\not\in T$, contradiction. So $r < q < s$.
\end{proof}

\begin{prop}
  There exists $x \in \R$ with $x^2 = 2$.
\end{prop}

\begin{proof}
  Let $S = \{r\in \R: r^2 \leq 2\}$. Then $0\in S$ so $S\not= \emptyset$. Also for every $r \in S$, we have $r \leq 3$. So $S$ is bounded above. So $x = \sup S$ exists and $0\leq x \leq 3$.

  By trichotomy, either $x^2 < 2, x^2 > 2$ or $x^2 = 2$.

  Suppose $x^2 < 2$. Let $0 < t < 1$. Then consider $(x + t)^2 = x^2 + 2xt + t^2 < x^2 + 6t + t \leq x^2 + 7t$. Pick $t < \frac{2 - x^2}{7}$, then $(x + t)^2 < 2$. So $x + t \in S$. This contradicts the fact that $x$ is an upper bound of $S$.

  Now suppose $x^2 > 2$. Let $0 < t < 1$. Then consider $(x - t)^2 = x^2 - 2xt + t^2 \geq x^2 - 6t$. Pick $t < \frac{x^2 - 2}{6}$. Then $(x - t)^2 > 2$, so $x - t$ is an upper bound for $S$. This contradicts the fact that $x$ is the least upper bound of $S$.

  So by trichotomy, $x^2 = 2$.
\end{proof}

\begin{remark}[Motivation for Dedekind cuts]
  Each bounded-above subset of $\Q$, such as $\{q \in \Q : q^2 < 2\}$, represents a ``missing number'' (here $\sqrt{2}$). To make the representation unique, we require the set to be \emph{downward closed}: if $x \in S$ and $y < x$, then $y \in S$. A rational $q$ is represented by the set $\{x \in \Q : x \leq q\}$.
\end{remark}

\begin{defi}[Dedekind cut]
  A \emph{Dedekind cut} of $\Q$ is a partition of $\Q$ into non-empty sets $L$ and $R$ such that
  \[
    (\forall l \in L)(\forall r \in R)\, l < r,
  \]
  and $R$ has no minimum.
\end{defi}

\begin{remark}
  The requirement that $R$ has no minimum corresponds to the convention that each rational $q$ is embedded as
  \[
    q \mapsto (\{x \in \Q : x \leq q\},\; \{x \in \Q : x > q\}),
  \]
  rather than $q \mapsto (\{x \in \Q : x < q\},\; \{x \in \Q : x \geq q\})$.

  We define $\R$ to be the set of all Dedekind cuts. The supremum of a bounded set of reals is obtained by taking the union of the left parts of the corresponding cuts. The arithmetic operations can be defined directly on cuts; the verification is tedious but straightforward.
\end{remark}

\subsection{Sequences}
\begin{remark}
  This and the next subsection give a brief introduction to sequences and series; the topics are treated in full generality in IA Analysis I.
\end{remark}

\begin{defi}[Sequence]
  A \emph{sequence} is a function $\N \to \R$. If $a$ is a sequence, we write $a_n$ instead of $a(n)$, and $(a_n)$ for the sequence itself.
\end{defi}

\begin{defi}[Limit of sequence]
  The sequence $(a_n)$ \emph{tends to} $l\in \R$ as $n$ tends to infinity if and only if
  \[
    (\forall \varepsilon > 0)(\exists N \in \N)(\forall n \geq N)\,|a_n - l| < \varepsilon.
  \]
  If $a_n$ tends to $l$ as $n$ tends to infinity, we write $a_n \to l$ as $n \to \infty$, or $\displaystyle \lim_{n \to \infty} a_n = l$.
\end{defi}

\begin{remark}
  The negation $a_n \not\to l$ is:
  \[
    (\exists \varepsilon > 0)(\forall N \in \N)(\exists n \geq N)\, |a_n - l| \geq \varepsilon.
  \]
\end{remark}

\begin{defi}[Convergence of sequence]
  The sequence $(a_n)$ \emph{converges} if there exists $l$ such that $a_n \to l$. The sequence \emph{diverges} if it does not converge.
\end{defi}
\begin{eg}
  Show that $a_n = 1 - \frac{1}{n} \to 1$.

  Given $\varepsilon > 0$, choose $N > \frac{1}{\varepsilon}$ (which exists by the Archimedean property). If $n \geq N$, then $|a_n - 1| = \frac{1}{n} \leq \frac{1}{N} < \varepsilon$. So $a_n \to 1$.
\end{eg}

\begin{eg}
  Let
  \[
    a_n = \begin{cases}\frac{1}{n} & n\text{ is prime}\\ \frac{1}{2n} & n\text{ is not prime}\end{cases}.
  \]
  We will show that $a_n \to 0$. Given $\varepsilon > 0$. Choose $N > \frac{1}{\varepsilon}$. Then $\forall n\geq N$, $|a_n - 0| \leq \frac{1}{n} < \varepsilon$.
\end{eg}

\begin{eg}
  Prove that
  \[
    a_n = \begin{cases}1 & n\text{ is prime}\\ 0 & n\text{ is not prime}\end{cases}
  \]
  diverges.

  Let $\varepsilon = \frac{1}{3}$. Suppose $l\in \R$. If $l < \frac{1}{2}$, then $|a_n - l| > \varepsilon$ when $n$ is prime. If $l\geq \frac{1}{2}$, then $|a_n - l| > \varepsilon$ when $n$ is not prime. Since the primes and non-primes are unbounded, $(\forall N)\exists n > N$ such that $|a_n - l| > \varepsilon$. So $a_n$ diverges.
\end{eg}

\begin{defi}[Monotonic and bounded sequences]
  A sequence $(a_n)$ is \emph{increasing} if $m \leq n$ implies $a_m \leq a_n$, and \emph{decreasing} if $m \leq n$ implies $a_m \geq a_n$. It is \emph{monotonic} if it is increasing or decreasing. It is \emph{bounded} if there exists $B \in \R$ with $|a_n| \leq B$ for all $n$.
\end{defi}

\begin{thm}
  Every bounded monotonic sequence converges.
\end{thm}

\begin{proof}
  Without loss of generality assume $(a_n)$ is increasing. The set $\{a_n : n \geq 1\}$ is non-empty and bounded above, so it has a supremum $l$ by the least upper bound axiom.

  Given $\varepsilon > 0$, $l - \varepsilon$ is not an upper bound, so there exists $N$ with $a_N > l - \varepsilon$. Since $(a_n)$ is increasing, for all $m \geq N$ we have $l \geq a_m \geq a_N > l - \varepsilon$, so $|a_m - l| < \varepsilon$. Hence $a_n \to l$.
\end{proof}

\begin{remark}
  This theorem is equivalent to the least upper bound axiom.
\end{remark}

\begin{defi}[Subsequence]
  A \emph{subsequence} of $(a_n)$ is a sequence of the form $(a_{g(n)})$, where $g\colon \N \to \N$ is strictly increasing. For example, $a_2, a_3, a_5, a_7, \ldots$ is a subsequence of $(a_n)$.
\end{defi}

\begin{thm}
  Every sequence has a monotonic subsequence.
\end{thm}

\begin{proof}
  Call a point $a_k$ a ``peak'' if $(\forall m \geq k)\,a_m \leq a_k$. If there are infinitely many peaks, then they form a decreasing subsequence. If there are only finitely many peaks, $\exists N$ such that no $a_n$ with $n > N$ is a peak. Pick $a_{N_1}$ with $N_1 > N$. Then pick $a_{N_2}$ with $N_2 > N_1$ and $a_{N_2} > a_{N_1}$. This is possible because $a_{N_1}$ is not a peak. Then pick $a_{N_3}$ with $N_3 > N_2$ and $a_{N_3}> a_{N_2}$, \emph{ad infinitum}. Then we have a monotonic subsequence.
\end{proof}

\begin{thm}[Algebra of limits]\leavevmode
  \begin{enumerate}
    \item If $a_n \to a$ and $a_n \to b$, then $a = b$ (i.e.\ limits are unique).
    \item If $a_n \to a$ and $b_n = a_n$ for all but finitely many $n$, then $b_n \to a$.
    \item If $a_n = a$ for all $n$, then $a_n \to a$.
    \item If $a_n \to a$ and $b_n \to b$, then $a_n + b_n \to a + b$.
    \item If $a_n \to a$ and $b_n \to b$, then $a_n b_n \to ab$.
    \item If $a_n \to a \neq 0$ and $a_n \neq 0$ for all $n$, then $1/a_n \to 1/a$.
    \item (\emph{Sandwich theorem}.) If $a_n \to a$ and $b_n \to a$, and $a_n \leq c_n \leq b_n$ for all $n$, then $c_n \to a$.
  \end{enumerate}
\end{thm}

\begin{remark}
  These properties verify that our $\varepsilon$-$N$ definition of convergence behaves as expected. The proofs make frequent use of the \emph{triangle inequality}: $|x + y| \leq |x| + |y|$.
\end{remark}
\begin{proof}\leavevmode
  \begin{enumerate}
    \item Suppose instead $a < b$. Choose $\varepsilon = \frac{b - a}{2}$. By the definition of the limit, $\exists N_1$ such that $\forall n \geq N_1$, $|a_n - a| < \varepsilon$, and $\exists N_2$ such that $\forall n \geq N_2$, $|a_n - b| < \varepsilon$.

      Let $N = \max\{N_1, N_2\}$. If $n\geq \max\{N_1, N_2\}$, then $|a - b| \leq |a - a_n| + |a_n - b| < 2\varepsilon = b - a.$
      Contradiction. So $a = b$.
    \item Given $\varepsilon > 0$, there exists $N_1$ such that $\forall n \geq N_1$, $|a_n - a| < \varepsilon$. Since $b_n = a_n$ for all but finitely many $n$, there exists $N_2$ such that $\forall n \geq N_2$, $a_n = b_n$.

      Let $N = \max\{N_1, N_2\}$. Then $\forall n\geq N$, we have $|b_n - a| = |a_n - a| < \varepsilon$. So $b_n\to a$.
    \item $\forall \varepsilon$, take $N = 1$. Then $|a_n - a| = 0 < \varepsilon$ for all $n \geq 1$.
    \item Given $\varepsilon > 0$, $\exists N_1$ such that $\forall n\geq N_1$, we have $|a_n - a| < \varepsilon/2$. Similarly, $\exists N_2$ such that $\forall n\geq N_2$, we have $|b_n - b| < \varepsilon/2$.

      Let $N = \max\{N_1, N_2\}$. Then $\forall n \geq N$, $|(a_n + b_n) - (a + b)| \leq |a_n - a| + |b_n - b| < \varepsilon$.
    \item Given $\varepsilon > 0$, choose $N_1, N_2, N_3$ such that
      \begin{align*}
        &\forall n \geq N_1\colon |a_n - a| < \frac{\varepsilon}{2(|b| + 1)},\\
        &\forall n \geq N_2\colon |b_n - b| < \frac{\varepsilon}{2(|a| + 1)},\\
        &\forall n \geq N_3\colon |b_n - b| < 1, \text{ so that } |b_n| < |b| + 1.
      \end{align*}
      Let $N = \max\{N_1, N_2, N_3\}$. Then $\forall n \geq N$,
      \begin{align*}
        |a_nb_n - ab| &= |b_n(a_n - a) + a(b_n - b)|\\
        &\leq |b_n| |a_n - a| + |a||b_n - b|\\
        &< (|b| + 1) |a_n - a| + |a||b_n - b|\\
        &< \frac{\varepsilon}{2} + \frac{\varepsilon}{2}\\
        &= \varepsilon
      \end{align*}
    \item Given $\varepsilon > 0$, choose $N_1$ such that $|a_n - a| < \frac{|a|^2}{2}\varepsilon$ for $n \geq N_1$, and $N_2$ such that $|a_n - a| < \frac{|a|}{2}$ for $n \geq N_2$ (so that $|a_n| > \frac{|a|}{2}$).

      Let $N = \max\{N_1, N_2\}$. Then $\forall n \geq N$,
      \begin{align*}
        \left|\frac{1}{a_n} - \frac{1}{a}\right| &= \frac{|a_n - a|}{|a_n||a|}\\
        &< \frac{2}{|a|^2}|a_n - a|\\
        &< \varepsilon
      \end{align*}
    \item By (iii) and (iv), $b_n - a_n \to a - a = 0$. Given $\varepsilon > 0$, choose $N$ such that $|b_n - a_n| < \varepsilon$ for all $n \geq N$. Since $0 \leq c_n - a_n \leq b_n - a_n$, we have $|c_n - a_n| < \varepsilon$, so $c_n - a_n \to 0$. Then $c_n = (c_n - a_n) + a_n \to 0 + a = a$ by (iv).\qedhere
  \end{enumerate}
\end{proof}

\begin{eg}
  Let $x_n = \frac{n^2(n + 1)(2n + 1)}{n^4 + 1}$. Then we have
  \[
    x_n = \frac{(1 + 1/n)(2 + 1/n)}{1 + 1/n^4}\to \frac{1\cdot 2}{1} = 2
  \]
  by the theorem (many times).
\end{eg}

\begin{eg}
  Let $y_n = \frac{100^n}{n!}$. Since $\frac{y_{n + 1}}{y_n} = \frac{100}{n + 1} < \frac{1}{2}$ for large $n > 200$, we know that $0 \leq y_n < y_{200}\cdot \frac{2^{200}}{2^n}$. Since $y_{200}\cdot \frac{2^{200}}{2^n} \to 0$, we know that $y_n\to 0$ as well.
\end{eg}

\subsection{Series}
In a field, the sum of two numbers is defined. By induction, the sum of finitely many numbers is defined as well. However, infinite sums (``series'') are not. We will define what it means to take an infinite sum. Of course, infinite sums exist only for certain nice sums. For example, $1 + 1 + 1 + \cdots$ does not exist.

\begin{defi}[Series and partial sums]
  Let $(a_n)$ be a sequence. Then $s_m = \sum_{n = 1}^m a_n$ is the \emph{$m$th partial sum} of $(a_n)$. We write
  \[
    \sum_{n = 1}^\infty a_n = \lim_{m\to \infty} s_m
  \]
  if the limit exists.
\end{defi}

\begin{eg}
  Let $a_n = \frac{1}{n(n - 1)}$ for $n\geq 2$. Then
  \[
    s_m = \sum_{n = 2}^m \frac{1}{n(n - 1)} = \sum_{n = 2}^m\left(\frac{1}{n - 1} - \frac{1}{n}\right) = 1 - \frac{1}{m}\to 1.
  \]
  Then
  \[
    \sum_{n = 2}^\infty \frac{1}{n(n - 1)} = 1.
  \]
\end{eg}

\begin{eg}
  Let $a_n = \frac{1}{n^2}$. Then $s_m = \sum_{n = 1}^{m} \frac{1}{n^2}$. We know that $s_m$ is increasing. We also know that $s_m \leq 1 + \sum \frac{1}{n(n -1)} \leq 2$, i.e.\ it is bounded above. So $s_m$ converges and $\sum_{n = 1}^{\infty} \frac{1}{n^2}$ exists (in fact it is $\pi^2/6$).
\end{eg}

\begin{eg}
  (Geometric series) Suppose $a_n = r^n$, where $|r| < 1$. Then $s_m = r\cdot \frac{1 - r^m}{1 - r} \to \frac{r}{1- r}$ since $r^n \to 0$. So
  \[
    \sum_{n = 1}^\infty r^n = \frac{r}{1 - r}.
  \]
\end{eg}

\begin{eg}
  (Harmonic series) Let $a_n = \frac{1}{n}$. Consider
  \begin{align*}
    S_{2^k} &= 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8} + \frac{1}{9} + \cdots + \frac{1}{2^k}\\
    & \geq 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{4} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{16} + \cdots + \frac{1}{2^k}\\
    &\geq 1 + \frac{k}{2}.
  \end{align*}
  So $\displaystyle \sum_{n = 1}^\infty\frac{1}{n}$ diverges.
\end{eg}

\subsubsection*{Decimal expansions}
\begin{defi}[Decimal expansion]
  Let $(d_n)$ be a sequence with $d_n\in \{0, 1, \cdots 9\}$. Then $\displaystyle \sum_{n = 1}^\infty \frac{d}{10^n}$ converges to a limit $r$ with $0 \leq r \leq 1$ since the partial sums $s_m$ are increasing and bounded by $\sum \frac{9}{10^n}\to 1$ (geometric series). We say $r = 0.d_1d_2d_3\cdots$, the \emph{decimal expansion} of $r$.
\end{defi}

Does every $x$ with $0 \leq x < 1$ have a decimal expansion?
Pick $d_1$ maximal such that $\frac{d_1}{10} \leq x < 1$. Then $0 \leq x - \frac{d_1}{10} < \frac{1}{10}$ since $d_1$ is maximal. Then pick $d_2$ maximal such that $\frac{d_2}{100} \leq x - \frac{d_1}{10}$. By maximality, $0 \leq x - \frac{d_1}{10} - \frac{d_2}{100} < \frac{1}{100}$. Repeat inductively, pick maximal $d_n$ with
\[
  \frac{d_n}{10^n} \leq x- \sum_{j = 1}^{n - 1} \frac{d_j}{10^j}
\]
so
\[
  0 \leq x - \sum_{j = 1}^n \frac{d_j}{10^j} < \frac{1}{10^n}.
\]
Since both LHS and RHS $\to 0$, by sandwich, $x - \sum_{j = 1}^\infty \frac{d_j}{10^j} = 0$, i.e.\ $x = 0.d_1d_2\cdots$.

Since we have shown that at least one decimal expansion, can the same number have two different decimal expansions? i.e.\ if $0.a_1a_2\cdots = 0.b_1b_2\cdots$, must $a_i = b_i$ for all $i$?

Now suppose that the $a_j$ and $b_j$ are equal until $k$, i.e.\ $a_j = b_j$ for $j < k$. wlog assume $a_k < b_k$. Then
\[
  \sum_{j = k + 1}^\infty \frac{a_j}{10^j} \leq \sum_{j = k+1}^\infty \frac{9}{10^j} = \frac{9}{10^{k+1}}\cdot \frac{1}{1 - 1/10} = \frac{1}{10^k}.
\]
So we must have $b_k = a_k + 1$, $a_j = 9$ for $j > k$ and $b_j = 0$ for $j > k$. For example, $0.47999\cdots = 0.48000\cdots$.

\subsection{Irrational numbers}
Recall $\Q\subseteq \R$.
\begin{defi}[Irrational number]
  Numbers in $\R\setminus \Q$ are \emph{irrational}.
\end{defi}

\begin{defi}[Periodic number]
  A decimal is \emph{periodic} if after a finite number $\ell$ of digits, it repeats in blocks of $k$ for some $k$, i.e.\ $d_{n + k} = d_n$ for $n > \ell$.
\end{defi}

\begin{prop}
  A number is periodic iff it is rational.
\end{prop}

\begin{proof}
  Clearly a periodic decimal is rational: Say $x = 0.7413157157157\cdots$. Then
  \begin{align*}
    10^\ell x &= 10^4x\\
    &= 7413.157157\cdots \\
    &= 7413 + 157\left(\frac{1}{10^3} + \frac{1}{10^6} + \frac{1}{10^9} + \cdots\right)\\
    &= 7413 + 157\cdot \frac{1}{10^3}\cdot \frac{1}{1 - 1/10^3}\in \Q
  \end{align*}
  Conversely, let $x\in \Q$. Then $x$ has a periodic decimal. Suppose $x = \frac{p}{2^c5^dq}$ with $(q, 10) = 1$. Then $10^{\max(c, d)}x = \frac{a}{q} = n + \frac{b}{q}$ for some $a, b, n\in \Z$ and $0\leq b < q$. However, since $(q, 10) = 1$, by Fermat-Euler, $10^{\phi(q)}\equiv 1\pmod q$, i.e.\ $10^{\phi(q)} - 1 = kq$ for some $k$. Then
  \[
    \frac{b}{q} = \frac{kb}{kq} = \frac{kb}{999\cdots 9} = kb\left(\frac{1}{10^{\phi(q)}} + \frac{1}{10^{2\phi(q)}} + \cdots \right).
  \]
  Since $kb < kq < 10^{\phi(q)}$, write $kb = d_1d_2\cdots d_{\phi(q)}$. So $\frac{b}{q} = 0.d_1d_2\cdots d_{\phi(q)}d_1d_2\cdots$ and $x$ is periodic.
\end{proof}

\begin{eg}
  $x = 0.01101010001010\cdots$, where $1$s appear in prime positions, is irrational since the digits don't repeat.
\end{eg}
\subsection{Euler's number}
\begin{defi}[Euler's number]
  \[
    e = \sum_{j=0}^\infty \frac{1}{j!} = 1 + \frac{1}{1!} + \frac{1}{2!} + \frac{1}{3!} + \cdots
  \]
\end{defi}
This sum exists because the partial sums are bounded by $1 + \frac{1}{1} + \frac{1}{2} + \frac{1}{4} + \frac{1}{8}\cdots = 3$ and it is increasing. So $2 < e < 3$.

\begin{prop}
  $e$ is irrational.
\end{prop}

\begin{proof}
  Is $e\in \Q$? Suppose $e = \frac{p}{q}$. We know $q\geq 2$ since $e$ is not an integer (it is between 2 and 3). Then $q!e \in \N$. But
  \[
    q!e = \underbrace{q! + q! + \frac{q!}{2!} + \frac{q!}{3!} + \cdots + \frac{q!}{q!}}_{n} + \underbrace{\frac{q!}{(q + 1)!} + \frac{q!}{(q + 2)!} + \cdots}_{x},
  \]
  where $n \in \N$. We also have
  \[
    x = \frac{1}{q + 1} + \frac{1}{(q + 1)(q + 2)} + \cdots.
  \]
  We can bound it by
  \[
    0 < x < \frac{1}{q+1} +\frac{1}{(q + 1)^2} + \frac{1}{(q + 1)^3} + \cdots = \frac{1}{q + 1}\cdot \frac{1}{1 - 1/(q + 1)} = \frac{1}{q} < 1.
  \]
  This is a contradiction since $q!e$ must be in $\N$ but it is a sum of an integer $n$ plus a non-integer $x$.
\end{proof}

\subsection{Algebraic numbers}
Rational numbers are ``nice'', because they can be written as fractions. Irrational numbers are bad. However, some irrational numbers are worse than others. We can further classify some irrational numbers as being \emph{transcendental}.
\begin{defi}[Algebraic and transcendental numbers]
  An \emph{algebraic number} is a root of a polynomial with integer coefficients (or rational coefficients). A number is \emph{transcendental} if it is not algebraic.
\end{defi}

\begin{prop}
  All rational numbers are algebraic.
\end{prop}

\begin{proof}
  Let $x = \frac{p}{q}$, then $x$ is a root of $qx - p = 0$.
\end{proof}

\begin{eg}
  $\sqrt{2}$ is irrational but algebraic since it is a root of $x^2 - 2 = 0$.
\end{eg}

So do transcendental numbers exist?
\begin{thm}
  (Liouville 1851; Non-examinable) $L$ is transcendental, where
  \[
    L = \sum_{n = 1}^\infty \frac{1}{10^{n!}} = 0.11000100\cdots
  \]
  with $1$s in the factorial positions.
\end{thm}

\begin{proof}
  Suppose instead that $f(L) = 0$ where $f(x) = a_kx^k + a_{k -1}x^{k - 1} + \cdots + a_0$, where $a_i\in \Z$, $a_k\not= 0$.

  For any rational $p/q$, we have
  \[
    f\left(\frac{p}{q}\right) = a_k\left(\frac{p}{q}\right)^k + \cdots + a_0 = \frac{\text{integer}}{q^k}.
  \]
  So if $p/q$ is not a root of $f$, then $|f(p/q)| \geq q^{-k}$.

  For any $m$, we can write $L = $ first $m$ terms + rest of the terms $ = s + t$.

  Now consider $|f(s)| = |f(L) - f(s)|$ (since $f(L) = 0$). We have
  \begin{align*}
    |f(L) - f(s)| &= \left|\sum a_i(L^i - s^i)\right|\\
    &\leq \sum |a_i(L^i - s^i)|\\
    &= \sum |a_i|(L - s)(L^{i - 1} + \cdots + s^{i - 1})\\
    &\leq \sum |a_i|(L - s)i,\\
    &= (L - s)\sum i|a_i|\\
    &= tC
  \end{align*}
  with $C = \sum i|a_i|$.

  Writing $s$ as a fraction, its denominator is at most $10^{m!}$. So $|f(s)| \geq 10^{-k\times m!}$. Combining with the above, we have $tC \geq 10^{-k\times m!}$.

  We can bound $t$ by
  \[
    t = \sum_{j = m + 1}^\infty 10^{-j!} \leq \sum_{\ell = (m + 1)!}^\infty 10^{-\ell} = \frac{10}{9}10^{-(m + 1)!}.
  \]
  So $(10C/9)10^{-(m + 1)!} \geq 10^{-k\times m!}$. Pick $m\in \N$ so that $m > k$ and $10^{m!} > \frac{10C}{9}$. This is always possible since both $k$ and $10C/9$ are constants. Then the inequality gives $10^{-(m + 1)} \geq 10^{-(k + 1)}$, which is a contradiction since $m > k$.
\end{proof}

\begin{thm}
  (Hermite 1873) $e$ is transcendental.
\end{thm}
\begin{thm}
  (Lindermann 1882) $\pi$ is transcendental.
\end{thm}

\section{Countability}
After messing with numbers, we finally get back to sets. Here we are concerned about the sizes of sets. We can count how big a set is by constructing bijections. Two sets have the same number of things if there is a bijection between them. In particular, a set has $n$ things if we can bijection it with $[n] = \{1, 2, 3, \cdots, n\}$.

First prove a few preliminary properties about bijecting with $[n]$ that should be obviously true.

\begin{lemma}
  If $f:[n] \to [n]$ is injective, then $f$ is bijective.
\end{lemma}

\begin{proof}
  Perform induction on $n$: It is true for $n = 1$. Suppose $n > 1$. Let $j = f(n)$. Define $g: [n]\to [n]$ by
  \[
    g(j) = n,\quad g(n) = j, \quad g(i) = i \text{ otherwise}.
  \]
  Then $g$ is a bijection. So the map $g\circ f$ is injective. It fixes $n$, i.e.\ $g\circ f(n) = n$. So the map $h:[n - 1]\to [n - 1]$ by $h(i) = g\circ f(i)$ is well-defined and injective. So $h$ is surjective. So $h$ is bijective. So $g\circ f$ is bijective. So is $f$.
\end{proof}

\begin{cor}
  If $A$ is a set and $f: A\to [n]$ and $g: A\to [m]$ are both bijections, then $m = n$.
\end{cor}

\begin{proof}
  wlog assume $m \geq n$. Let $h: [n]\to [m]$ with $h(i) = i$, which is injective. Then the map $h\circ f\circ g^{-1}: [m]\to [m]$ is injective. Then by the lemma this is surjective. So $h$ must be surjective. So $n\geq m$. Hence $n = m$.
\end{proof}
This shows that we cannot biject a set to two different numbers, or a set cannot have two different sizes!

\begin{defi}[Finite set and cardinality of set]
  The set $A$ is \emph{finite} if there exists a bijection $A\to [n]$ for some $n\in\N_0$. The \emph{cardinality} or \emph{size} of $A$, written as $|A|$, is $n$. By the above corollary, this is well-defined.
\end{defi}

\begin{lemma}
  Let $S\subseteq \N$. Then either $S$ is finite or there is a bijection $g:\N \to S$.
\end{lemma}

\begin{proof}
  If $S\not= \emptyset$, by the well-ordering principle, there is a least element $s_1\in S$. If $S\setminus \{s_1\} \not= \emptyset$, it has a least element $s_2$. If $S\setminus \{s_1, s_2\}$ is not empty, there is a least element $s_3$. If at some point the process stops, then $S = \{s_1, s_2,\cdots, s_n\}$, which is finite. Otherwise, if it goes on forever, the map $g: \N \to S$ given by $g(i) = s_i$ is well-defined and is an injection. It is also a surjection because if $k\in S$, then $k$ is a natural number and there are at most $k$ elements of $S$ less than $k$. So $k$ will be mapped to $s_i$ for some $i\leq k$.
\end{proof}

\begin{defi}[Countable set]
  A set $A$ is \emph{countable} if $A$ is finite or there is a bijection between $A$ and $\N$. A set $A$ is \emph{uncountable} if $A$ is not countable.
\end{defi}

This is one possible definition of countability, but there are some (often) more helpful definitions.
\begin{thm}
  The following are equivalent:
  \begin{enumerate}
    \item $A$ is countable
    \item There is an injection from $A\to \N$
    \item $A = \emptyset$ or there is a surjection from $\N \to A$
  \end{enumerate}
\end{thm}

\begin{proof}
  (i) $\Rightarrow$ (iii): If $A$ is finite, there is a bijection $f: A \to S$ for some $S\subseteq \N$. For all $x\in \N$, if $x\in S$, then map $x\mapsto f^{-1}(x)$. Otherwise, map $x$ to any element of $A$. This is a surjection since $\forall a\in A$, we have $f(a)\mapsto a$.

  (iii) $\Rightarrow$ (ii): If $A\not= \emptyset$ and $f: \N\to A$ is a surjection. Define a map $g: A\to \N$ by $g(a) = \min f^{-1}(\{a\})$, which exists by well-ordering. So $g$ is an injection.

  (ii) $\Rightarrow$ (i): If there is an injection $f: A\to \N$, then $f$ gives a bijection between $A$ and $S = f(A)\subseteq \N$. If $S$ is finite, so is $A$. If $S$ is infinite, there is a bijection $g$ between $S$ and $\N$. So there is a bijection $g\circ f$ between $A$ and $\N$.
\end{proof}

Often, the injection definition is the most helpful.

\begin{prop}
  The integers $\Z$ are countable.
\end{prop}
\begin{proof}
  The map $f: \Z\to \N$ given by
  \[
    f(n) =
    \begin{cases}
      2n & n > 0\\
      2(-n) + 1 & n \leq 0
    \end{cases}
  \]
  is a bijection.
\end{proof}

\begin{prop}
  $\N \times \N$ is countable.
\end{prop}
\begin{proof}
  We can map $(a, b)\mapsto 2^a3^b$ injectively by the fundamental theorem of arithmetic. So $\N\times \N$ is countable.

  We can also have a bijection by counting diagonally: $(a, b) \mapsto \binom{a + b}{2} - a + 1$:
  \begin{center}
    \begin{tikzpicture}[scale=1.8]
      \draw (0, 0) -- (0, 3.5);
      \draw (0, 0) -- (3.8, 0);
      \foreach \i in {1, 2, 3, 4} {
        \node [left] at (0, \i - 1) {\i};
        \node [below] at (\i - 1, 0) {\i};
      }

      \foreach \i in {1, 2, 3, 4} {
        \foreach \j in {1, 2, 3, 4} {
          \node [circ] at (\i - 1, \j - 1) {};
          \node [anchor = south west] at (\i - 1, \j - 1) {\pgfmathparse{(\i + \j)*(\i + \j - 1) / 2 - \i + 1}\pgfmathprintnumber{\pgfmathresult}};
        }
      }

      \draw [dashed] (1, 0) -- (0, 1);
      \draw [dashed] (2, 0) -- (0, 2);
      \draw [dashed] (3, 0) -- (0, 3);
      \draw [dashed] (3.8, 0.2) -- (.5, 3.5);
      \draw [dashed] (3.8, 1.2) -- (1.5, 3.5);
    \end{tikzpicture}
  \end{center}
\end{proof}

Since $\Z$ is countable, we have an injection $\Z\to \N$, so there is an injection from $\Z\times \N\to \N\times \N \to \N$. So $\Z \times \N$ is countable. However, the rationals are the equivalence classes of $\Z\times\N$. So $\Q$ is countable.

\begin{prop}
  If $A\to B$ is injective and $B$ is countable, then $A$ is countable (since we can inject $B \to \N$).
\end{prop}

\begin{prop}
  $\Z^k$ is countable for all $k\in \N$
\end{prop}

\begin{proof}
  Proof by induction: $\Z$ is countable. If $\Z^k$ is countable, $\Z^{k + 1} = \Z\times \Z^k$. Since we can map $\Z^k \to \N$ injectively by the induction hypothesis, we can map injectively $\Z^{k + 1}\to \Z\times \N$, and we can map that to $\N$ injectively.
\end{proof}

\begin{thm}
  A countable union of countable sets is countable.
\end{thm}

\begin{proof}
  Let $I$ be a countable index set, and for each $\alpha \in I$, let $A_\alpha$ be a countable set. We need to show that $\bigcup_{\alpha\in I} A_\alpha$ is countable. It is enough to construct an injection $h: \bigcup_{\alpha\in I} A_\alpha \to \N\times \N$ because $\N\times\N$ is countable. We know that $I$ is countable. So there exists an injection $f: I\to \N$. For each $\alpha\in I$, there exists an injection $g_\alpha: A_\alpha \to\N$.

  For $a\in \bigcup A_\alpha$, pick $m = \min\{j\in \N: a\in A_{\alpha}\text{ and }f(\alpha) = j\}$, and let $\alpha$ be the corresponding index such that $f(\alpha) = m$. We then set $h(a) = (m, g_\alpha(a))$, and this is an injection.
\end{proof}

\begin{prop}
  $\Q$ is countable.
\end{prop}
\begin{proof}
  It can be proved in two ways:
  \begin{enumerate}
    \item $\Q = \bigcup_{n\geq 1} \frac{1}{n}\Z = \bigcup_{n\geq 1} \left\{\frac{m}{n}: m\in \Z\right\}$, which is a countable union of countable sets.
    \item $\Q$ can be mapped injectively to $\Z\times \N$ by $a/b\mapsto (a, b)$, where $b > 0$ and $(a, b) = 1$.\qedhere
  \end{enumerate}
\end{proof}

\begin{thm}
  The set of algebraic numbers is countable.
\end{thm}
\begin{proof}
  Let $\mathcal{P}_k$ be the set of polynomials of degree $k$ with integer coefficients. Then $a_kx^k + a_{k - 1}x^{k - 1} + \cdots + a_0 \mapsto (a_k, a_{k - 1}, \cdots, a_0)$ is an injection $\mathcal{P}_k \to \Z^{k + 1}$. Since $\Z^{k + 1}$ is countable, so is $\mathcal{P}_k$.

  Let $\mathcal{P}$ be the set of all polynomials with integer coefficients. Then clearly $\mathcal{P} = \bigcup \mathcal{P}_k$. This is a countable union of countable sets. So $\mathcal{P}$ is countable.

  For each polynomial $p \in \mathcal{P}$, let $R_p$ be the set of its roots. Then $R_p$ is finite and thus countable. Hence $\bigcup_{p\in \mathcal{P}} R_p$, the set of all algebraic numbers, is countable.
\end{proof}

\begin{thm}
  The set of real numbers $\R$ is uncountable.
\end{thm}

\begin{proof}
  (Cantor's diagonal argument) Assume $\R$ is countable. Then we can list the reals as $r_1,r_2,r_3\cdots$ so that every real number is in the list. Write each $r_n$ uniquely in decimal form (i.e.\ without infinite trailing '9's). List them out vertically:
  \begin{align*}
    r_1 &= n_1\,.\,d_{11}\,d_{12}\,d_{13}\,d_{14}\cdots\\
    r_2 &= n_2\,.\,d_{21}\,d_{22}\,d_{23}\,d_{24}\cdots\\
    r_3 &= n_3\,.\,d_{31}\,d_{32}\,d_{33}\,d_{34}\cdots\\
    r_4 &= n_4\,.\,d_{41}\,d_{42}\,d_{43}\,d_{44}\cdots
  \end{align*}
  Define $r = 0\,.\,d_1\,d_2\,d_3\,d_4\cdots$ by $d_n =
  \begin{cases}
    0 & d_{nn}\not= 0\\
    1 & d_{nn}=0
  \end{cases}$. Then by construction, this differs from the $n$th number in the list by the $n$th digit, and is so different from every number in the list. Then $r$ is a real number but not in the list. Contradiction.
\end{proof}

\begin{cor}
  There are uncountable many transcendental numbers.
\end{cor}

\begin{proof}
  If not, then the reals, being the union of the transcendentals and algebraic numbers, must be countable. But the reals is uncountable.
\end{proof}
This is an easy but non-constructive proof that transcendental numbers exists. ``If we can't find one, find lots!'' (it is debatable whether this proof is constructive or not. Some argue that we can use this to construct a transcendental number by listing all the algebraic numbers and perform the diagonal argument to obtain a number not in the list, i.e.\ a transcendental number. So this is in fact constructive)

\begin{eg}
  Let $\mathcal{F}_k = \{Y\subseteq \N: |Y| = k\}$, i.e.\ the set of all subsets of $\N$ of size $k$. We can inject $\mathcal{F}_k \to \Z^k$ in the obvious way, e.g.\ $\{1, 3, 7\}\mapsto (1, 3, 7)$ etc. So it is countable. So $\mathcal{F} = \bigcup_{k\geq 0}\mathcal{F}_k$, the set of all finite subsets of $\N$ is countable.
\end{eg}

\begin{eg}
  Recall $\mathcal{P}(X) = \{Y: Y\subseteq X\}$. Now suppose $\mathcal{P}(\N)$ is countable. Let $S_1,S_2,S_3, \cdots$ be the list of all subsets of $\N$. Let $S = \{n: n\not\in S_n\}$. But then $S$ is not in the list. Contradiction. So $\mathcal{P}(\N)$ is uncountable.
\end{eg}

\begin{eg}
  Let $\Sigma$ be the set of all functions $\N\to \N$ (i.e.\ the set of all integer sequences). If $\Sigma$ were countable, we could list it as $f_1, f_2, f_3\cdots$. But then consider $f$ given by $f(n) =
  \begin{cases}
    1 & f_n(n) \not= 1\\
    2 & f_n(n) = 1
  \end{cases}$. Again $f$ is not in the list. Contradiction. So $\Sigma$ is uncountable.

  Alternatively, there is a bijection between $\mathcal{P}(\N)$ and the set of 0, 1 sequences by $S\mapsto$ the indicator function. So we can inject $\mathcal{P}(\N) \to \Sigma$ by $S\mapsto $ indicator function $+1$. So $\Sigma$ cannot be countable (since $\mathcal{P}(\N)$ is uncountable).

  Or, we can let $\Sigma^*\subseteq \Sigma$ be the set of bijections from $\N\to\N$. Let $\Sigma^{**}\subseteq \Sigma^*$ be the bijections of the special form: for every $n$,
  \[
    \text{either}
    \begin{cases}
      f(2n - 1) = 2n - 1\\
      f(2n) = 2n
    \end{cases}\text{, or }
    \begin{cases}
      f(2n - 1) = 2n\\
      f(2n) = 2n - 1
    \end{cases},
  \]
  i.e.\ for every odd-even pair, we either flip them or keep them the same.

  But there is a bijection between $\Sigma^{**}$ and $0,1$ sequences: if the $n$th term in the sequence $ = 0$, don't flip the $n$th pair in the function, vice versa. Hence $\Sigma^{**}$ is uncountable.
\end{eg}

\begin{thm}
  Let $A$ be a set. Then there is no surjection from $A\to \mathcal{P}(A)$.
\end{thm}

\begin{proof}
  Suppose $f: A\to \mathcal{P}(A)$ is surjective. Let $S = \{a\in A: a\not\in f(a)\}$. Since $f$ is surjective, there must exist $s\in A$ such that $f(s) = S$. If $s\in S$, then $s\not\in S$ by the definition of $S$. Conversely, if $s\not\in S$, then $s\in S$. Contradiction. So $f$ cannot exist.
\end{proof}

This shows that there are infinitely many different possible ``infinite sizes'' of sets.

We conclude by two theorems that we will not prove.
\begin{thm}[Cantor-Schr\"oder-Bernstein theorem]
  Suppose there are injections $A\to B$ and $B\to A$. Then there's a bijection $A\leftrightarrow B$.
\end{thm}

\noindent \textbf{Continuum hypothesis.} There is no set whose size lies between $\N$ and $\R$. In 1963, Paul Cohen proved that it is impossible to prove this or disprove this statement (in ZFC). The proof can be found in the Part III Topics in Set Theory course.
\end{document}
